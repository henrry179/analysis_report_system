#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•ç³»ç»Ÿ
æµ‹è¯•æ‰€æœ‰å¢å¼ºåŠŸèƒ½æ¨¡å—çš„å®Œæ•´æ€§å’Œæ€§èƒ½
"""

import os
import sys
import time
import json
import traceback
from datetime import datetime
from typing import Dict, List, Any, Tuple
from pathlib import Path

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.append('src')

class ComprehensiveTestSuite:
    """ç»¼åˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'test_details': [],
            'performance_metrics': {},
            'start_time': None,
            'end_time': None
        }
        self.output_dir = "output/test_results"
        os.makedirs(self.output_dir, exist_ok=True)
        
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è¿è¡Œç»¼åˆæµ‹è¯•å¥—ä»¶...")
        print("=" * 80)
        
        self.test_results['start_time'] = datetime.now()
        
        # æµ‹è¯•æ¨¡å—åˆ—è¡¨
        test_modules = [
            ('æ•°æ®å¤„ç†æ¨¡å—', self.test_data_processing),
            ('åˆ†æå¼•æ“æ¨¡å—', self.test_analytics_engine),
            ('å¯è§†åŒ–æ¨¡å—', self.test_visualization),
            ('æŠ¥å‘Šç”Ÿæˆæ¨¡å—', self.test_report_generation),
            ('ä¸»ç³»ç»Ÿé›†æˆ', self.test_main_system),
            ('æ€§èƒ½æµ‹è¯•', self.test_performance),
            ('é”™è¯¯å¤„ç†', self.test_error_handling),
            ('ä¾èµ–æ£€æµ‹', self.test_dependency_detection)
        ]
        
        for module_name, test_function in test_modules:
            print(f"\nğŸ“‹ æµ‹è¯•æ¨¡å—: {module_name}")
            print("-" * 50)
            
            try:
                test_function()
            except Exception as e:
                self._record_test_failure(module_name, f"æ¨¡å—æµ‹è¯•å¤±è´¥: {str(e)}")
                print(f"âŒ {module_name} æµ‹è¯•å¤±è´¥: {e}")
                traceback.print_exc()
        
        self.test_results['end_time'] = datetime.now()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self._generate_test_report()
        
        # æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦
        self._display_test_summary()
        
        return self.test_results
    
    def test_data_processing(self):
        """æµ‹è¯•æ•°æ®å¤„ç†æ¨¡å—"""
        try:
            from src.data.enhanced_data_processor import EnhancedDataProcessor
            
            processor = EnhancedDataProcessor()
            
            # æµ‹è¯•1: åŸºæœ¬åˆå§‹åŒ–
            self._run_test("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–", lambda: processor is not None)
            
            # æµ‹è¯•2: æ•°æ®éªŒè¯
            mock_data = self._create_mock_dataframe()
            validation_result = processor.validate_data_structure(mock_data)
            self._run_test("æ•°æ®ç»“æ„éªŒè¯", lambda: 'is_valid' in validation_result)
            
            # æµ‹è¯•3: æ•°æ®æ¸…æ´—
            cleaned_data, cleaning_report = processor.clean_data(mock_data)
            self._run_test("æ•°æ®æ¸…æ´—åŠŸèƒ½", lambda: cleaning_report['operations_performed'] is not None)
            
            # æµ‹è¯•4: æ•°æ®è½¬æ¢
            transformed_data, transform_report = processor.transform_data(cleaned_data)
            self._run_test("æ•°æ®è½¬æ¢åŠŸèƒ½", lambda: transform_report['transformations_applied'] is not None)
            
            # æµ‹è¯•5: æ•°æ®æ¦‚å†µç”Ÿæˆ
            profile = processor.generate_data_profile(transformed_data)
            self._run_test("æ•°æ®æ¦‚å†µç”Ÿæˆ", lambda: 'summary' in profile)
            
            # æµ‹è¯•6: å®Œæ•´æµæ°´çº¿
            pipeline_data, pipeline_results = processor.process_pipeline(mock_data)
            self._run_test("å®Œæ•´å¤„ç†æµæ°´çº¿", lambda: 'processing_time' in pipeline_results)
            
            print("âœ… æ•°æ®å¤„ç†æ¨¡å—æµ‹è¯•å®Œæˆ")
            
        except ImportError:
            self._record_test_failure("æ•°æ®å¤„ç†æ¨¡å—", "æ¨¡å—å¯¼å…¥å¤±è´¥")
        except Exception as e:
            self._record_test_failure("æ•°æ®å¤„ç†æ¨¡å—", str(e))
    
    def test_analytics_engine(self):
        """æµ‹è¯•åˆ†æå¼•æ“æ¨¡å—"""
        try:
            from src.analysis.advanced_analytics_engine import AdvancedAnalyticsEngine
            
            engine = AdvancedAnalyticsEngine()
            mock_data = self._create_mock_dataframe()
            
            # æµ‹è¯•1: ç›¸å…³æ€§åˆ†æ
            features = ['gmv', 'dau', 'conversion_rate']
            correlation_result = engine.correlation_analysis(mock_data, features)
            self._run_test("ç›¸å…³æ€§åˆ†æ", lambda: 'correlation_matrix' in correlation_result)
            
            # æµ‹è¯•2: è¶‹åŠ¿åˆ†æ
            trend_result = engine.trend_analysis(mock_data, 'gmv')
            self._run_test("è¶‹åŠ¿åˆ†æ", lambda: 'trend_direction' in trend_result)
            
            # æµ‹è¯•3: å¼‚å¸¸æ£€æµ‹
            anomaly_result = engine.anomaly_detection(mock_data, 'gmv')
            self._run_test("å¼‚å¸¸æ£€æµ‹", lambda: 'anomalies_detected' in anomaly_result)
            
            # æµ‹è¯•4: ç”¨æˆ·åˆ†ç¾¤
            segmentation_result = engine.advanced_segmentation(mock_data, features)
            self._run_test("ç”¨æˆ·åˆ†ç¾¤", lambda: 'segments' in segmentation_result)
            
            print("âœ… åˆ†æå¼•æ“æ¨¡å—æµ‹è¯•å®Œæˆ")
            
        except ImportError:
            self._record_test_failure("åˆ†æå¼•æ“æ¨¡å—", "æ¨¡å—å¯¼å…¥å¤±è´¥")
        except Exception as e:
            self._record_test_failure("åˆ†æå¼•æ“æ¨¡å—", str(e))
    
    def test_visualization(self):
        """æµ‹è¯•å¯è§†åŒ–æ¨¡å—"""
        try:
            from src.visualization.enhanced_chart_generator import EnhancedChartGenerator
            
            generator = EnhancedChartGenerator()
            mock_data = self._create_mock_chart_data()
            
            # æµ‹è¯•1: é«˜çº§ä»ªè¡¨æ¿åˆ›å»º
            dashboard_result = generator.create_advanced_dashboard(mock_data, self.output_dir)
            self._run_test("é«˜çº§ä»ªè¡¨æ¿åˆ›å»º", lambda: 'charts_created' in dashboard_result)
            
            # æµ‹è¯•2: ä¸“ä¸šå›¾è¡¨åˆ›å»º
            chart_types = ['correlation_heatmap', 'funnel_chart']
            charts_result = generator.create_specialized_charts(mock_data, chart_types, self.output_dir)
            self._run_test("ä¸“ä¸šå›¾è¡¨åˆ›å»º", lambda: 'charts_created' in charts_result)
            
            print("âœ… å¯è§†åŒ–æ¨¡å—æµ‹è¯•å®Œæˆ")
            
        except ImportError:
            self._record_test_failure("å¯è§†åŒ–æ¨¡å—", "æ¨¡å—å¯¼å…¥å¤±è´¥")
        except Exception as e:
            self._record_test_failure("å¯è§†åŒ–æ¨¡å—", str(e))
    
    def test_report_generation(self):
        """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆæ¨¡å—"""
        try:
            from src.reports.intelligent_report_generator import IntelligentReportGenerator
            
            generator = IntelligentReportGenerator()
            mock_data = self._create_mock_data()
            mock_analysis = self._create_mock_analysis_results()
            
            # æµ‹è¯•1: ç»¼åˆæŠ¥å‘Šç”Ÿæˆ
            report_result = generator.generate_comprehensive_report(
                mock_data, mock_analysis, self.output_dir, 
                formats=['html', 'markdown', 'json', 'executive']
            )
            self._run_test("ç»¼åˆæŠ¥å‘Šç”Ÿæˆ", lambda: len(report_result['reports_generated']) > 0)
            
            # æµ‹è¯•2: æ´å¯Ÿç”Ÿæˆ
            insights = generator.insight_engine.generate_insights(mock_data, mock_analysis)
            self._run_test("æ™ºèƒ½æ´å¯Ÿç”Ÿæˆ", lambda: 'insights' in insights)
            
            # æµ‹è¯•3: å»ºè®®ç”Ÿæˆ
            recommendations = generator.insight_engine.generate_recommendations(
                mock_data, mock_analysis, insights
            )
            self._run_test("è¡ŒåŠ¨å»ºè®®ç”Ÿæˆ", lambda: 'recommendations' in recommendations)
            
            print("âœ… æŠ¥å‘Šç”Ÿæˆæ¨¡å—æµ‹è¯•å®Œæˆ")
            
        except ImportError:
            self._record_test_failure("æŠ¥å‘Šç”Ÿæˆæ¨¡å—", "æ¨¡å—å¯¼å…¥å¤±è´¥")
        except Exception as e:
            self._record_test_failure("æŠ¥å‘Šç”Ÿæˆæ¨¡å—", str(e))
    
    def test_main_system(self):
        """æµ‹è¯•ä¸»ç³»ç»Ÿé›†æˆ"""
        try:
            from src.main import main
            
            # æµ‹è¯•ä¸»ç³»ç»Ÿè¿è¡Œ
            result = main()
            self._run_test("ä¸»ç³»ç»Ÿè¿è¡Œ", lambda: result is not None)
            
            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
            output_exists = os.path.exists("output") and len(os.listdir("output")) > 0
            self._run_test("è¾“å‡ºæ–‡ä»¶ç”Ÿæˆ", lambda: output_exists)
            
            print("âœ… ä¸»ç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆ")
            
        except ImportError:
            self._record_test_failure("ä¸»ç³»ç»Ÿé›†æˆ", "æ¨¡å—å¯¼å…¥å¤±è´¥")
        except Exception as e:
            self._record_test_failure("ä¸»ç³»ç»Ÿé›†æˆ", str(e))
    
    def test_performance(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        print("âš¡ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
        
        # æµ‹è¯•1: ç³»ç»Ÿå¯åŠ¨æ—¶é—´
        start_time = time.time()
        try:
            from src.main import main
            main()
            startup_time = time.time() - start_time
            self.test_results['performance_metrics']['startup_time'] = startup_time
            self._run_test("ç³»ç»Ÿå¯åŠ¨æ€§èƒ½", lambda: startup_time < 10.0)  # 10ç§’å†…å¯åŠ¨
            print(f"ğŸ“Š ç³»ç»Ÿå¯åŠ¨æ—¶é—´: {startup_time:.2f}ç§’")
        except Exception as e:
            self._record_test_failure("ç³»ç»Ÿå¯åŠ¨æ€§èƒ½", str(e))
        
        # æµ‹è¯•2: å†…å­˜ä½¿ç”¨
        try:
            import psutil
            memory_percent = psutil.virtual_memory().percent
            self.test_results['performance_metrics']['memory_usage'] = memory_percent
            self._run_test("å†…å­˜ä½¿ç”¨ç‡", lambda: memory_percent < 80.0)  # å†…å­˜ä½¿ç”¨ç‡ä½äº80%
            print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡: {memory_percent:.1f}%")
        except ImportError:
            print("âš ï¸ psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        
        # æµ‹è¯•3: æ–‡ä»¶ç”Ÿæˆé€Ÿåº¦
        start_time = time.time()
        try:
            # æ¨¡æ‹Ÿæ–‡ä»¶ç”Ÿæˆæµ‹è¯•
            test_file = os.path.join(self.output_dir, "performance_test.txt")
            with open(test_file, 'w') as f:
                for i in range(1000):
                    f.write(f"æµ‹è¯•è¡Œ {i}\n")
            file_generation_time = time.time() - start_time
            self.test_results['performance_metrics']['file_generation_time'] = file_generation_time
            self._run_test("æ–‡ä»¶ç”Ÿæˆæ€§èƒ½", lambda: file_generation_time < 1.0)  # 1ç§’å†…å®Œæˆ
            print(f"ğŸ“ æ–‡ä»¶ç”Ÿæˆæ—¶é—´: {file_generation_time:.3f}ç§’")
        except Exception as e:
            self._record_test_failure("æ–‡ä»¶ç”Ÿæˆæ€§èƒ½", str(e))
        
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("ğŸ›¡ï¸ å¼€å§‹é”™è¯¯å¤„ç†æµ‹è¯•...")
        
        # æµ‹è¯•1: æ— æ•ˆæ•°æ®å¤„ç†
        try:
            from src.data.enhanced_data_processor import EnhancedDataProcessor
            processor = EnhancedDataProcessor()
            
            # æµ‹è¯•Noneæ•°æ®
            result = processor.validate_data_structure(None)
            self._run_test("Noneæ•°æ®å¤„ç†", lambda: result is not None)
            
            # æµ‹è¯•ç©ºæ•°æ®
            result = processor.validate_data_structure({})
            self._run_test("ç©ºæ•°æ®å¤„ç†", lambda: result is not None)
            
        except Exception as e:
            self._record_test_failure("é”™è¯¯å¤„ç†æµ‹è¯•", str(e))
        
        # æµ‹è¯•2: æ¨¡å—ç¼ºå¤±å¤„ç†
        try:
            # æ¨¡æ‹Ÿæ¨¡å—å¯¼å…¥é”™è¯¯
            import sys
            original_modules = sys.modules.copy()
            
            # æš‚æ—¶ç§»é™¤æŸä¸ªæ¨¡å—
            if 'pandas' in sys.modules:
                del sys.modules['pandas']
            
            # æµ‹è¯•ç³»ç»Ÿåœ¨ç¼ºå°‘ä¾èµ–æ—¶çš„è¡¨ç°
            from src.main import main
            result = main()
            self._run_test("ç¼ºå¤±ä¾èµ–å¤„ç†", lambda: result is not None)
            
            # æ¢å¤æ¨¡å—
            sys.modules.update(original_modules)
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å—ç¼ºå¤±æµ‹è¯•: {e}")
        
        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆ")
    
    def test_dependency_detection(self):
        """æµ‹è¯•ä¾èµ–æ£€æµ‹"""
        print("ğŸ” å¼€å§‹ä¾èµ–æ£€æµ‹æµ‹è¯•...")
        
        dependencies = [
            ('pandas', 'Level 2+ æ•°æ®å¤„ç†'),
            ('matplotlib', 'Level 2+ å¯è§†åŒ–'),
            ('numpy', 'Level 2+ æ•°å€¼è®¡ç®—'),
            ('jinja2', 'Level 2+ æ¨¡æ¿å¼•æ“'),
            ('fastapi', 'Level 2+ Webæ¡†æ¶'),
            ('plotly', 'Level 3 äº¤äº’å¼å›¾è¡¨'),
            ('sklearn', 'Level 3 æœºå™¨å­¦ä¹ ')
        ]
        
        dependency_status = {}
        
        for dep_name, dep_desc in dependencies:
            try:
                __import__(dep_name)
                dependency_status[dep_name] = {'available': True, 'description': dep_desc}
                print(f"âœ… {dep_name}: å¯ç”¨ ({dep_desc})")
            except ImportError:
                dependency_status[dep_name] = {'available': False, 'description': dep_desc}
                print(f"âŒ {dep_name}: ä¸å¯ç”¨ ({dep_desc})")
        
        self.test_results['performance_metrics']['dependency_status'] = dependency_status
        
        # è®¡ç®—å¯ç”¨æ€§ç­‰çº§
        level_0_deps = []  # é›¶ä¾èµ–
        level_2_deps = ['pandas', 'matplotlib', 'numpy', 'jinja2', 'fastapi']
        level_3_deps = ['plotly', 'sklearn']
        
        level_2_available = sum(1 for dep in level_2_deps if dependency_status.get(dep, {}).get('available', False))
        level_3_available = sum(1 for dep in level_3_deps if dependency_status.get(dep, {}).get('available', False))
        
        if level_2_available >= 3:
            system_level = "Level 2 (æ ‡å‡†åŠŸèƒ½)"
        elif level_3_available >= 1:
            system_level = "Level 3 (å®Œæ•´åŠŸèƒ½)"
        else:
            system_level = "Level 0 (é›¶ä¾èµ–æ¨¡å¼)"
        
        print(f"ğŸ† ç³»ç»ŸåŠŸèƒ½ç­‰çº§: {system_level}")
        self.test_results['performance_metrics']['system_level'] = system_level
        
        self._run_test("ä¾èµ–æ£€æµ‹åŠŸèƒ½", lambda: True)  # æ€»æ˜¯é€šè¿‡ï¼Œå› ä¸ºæ£€æµ‹æœ¬èº«å°±æ˜¯æˆåŠŸçš„
        
        print("âœ… ä¾èµ–æ£€æµ‹æµ‹è¯•å®Œæˆ")
    
    def _run_test(self, test_name: str, test_func) -> bool:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        self.test_results['total_tests'] += 1
        
        try:
            start_time = time.time()
            result = test_func()
            end_time = time.time()
            
            if result:
                self.test_results['passed_tests'] += 1
                status = "âœ… PASS"
                print(f"  {status} {test_name} ({end_time - start_time:.3f}s)")
                
                self.test_results['test_details'].append({
                    'name': test_name,
                    'status': 'PASS',
                    'duration': end_time - start_time,
                    'timestamp': datetime.now().isoformat()
                })
                return True
            else:
                self._record_test_failure(test_name, "æµ‹è¯•æ¡ä»¶ä¸æ»¡è¶³")
                return False
                
        except Exception as e:
            self._record_test_failure(test_name, str(e))
            return False
    
    def _record_test_failure(self, test_name: str, error_message: str):
        """è®°å½•æµ‹è¯•å¤±è´¥"""
        self.test_results['failed_tests'] += 1
        status = "âŒ FAIL"
        print(f"  {status} {test_name}: {error_message}")
        
        self.test_results['test_details'].append({
            'name': test_name,
            'status': 'FAIL',
            'error': error_message,
            'timestamp': datetime.now().isoformat()
        })
    
    def _create_mock_dataframe(self):
        """åˆ›å»ºæ¨¡æ‹ŸDataFrame"""
        try:
            import pandas as pd
            import numpy as np
            
            return pd.DataFrame({
                'date': pd.date_range('2024-01-01', periods=100),
                'gmv': np.random.normal(800000, 100000, 100),
                'dau': np.random.normal(1000, 200, 100),
                'conversion_rate': np.random.normal(3.0, 0.5, 100),
                'category': np.random.choice(['ç”µå­äº§å“', 'æœè£…', 'å®¶å±…'], 100),
                'region': np.random.choice(['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'], 100)
            })
        except ImportError:
            # è¿”å›æ¨¡æ‹Ÿå¯¹è±¡
            class MockDataFrame:
                def __init__(self):
                    self.data = {
                        'gmv': [800000, 850000, 820000, 880000],
                        'dau': [1000, 1100, 950, 1050],
                        'conversion_rate': [3.0, 3.2, 2.8, 3.5]
                    }
                    self.columns = list(self.data.keys())
                    self.shape = (4, 3)
            
            return MockDataFrame()
    
    def _create_mock_chart_data(self) -> Dict[str, Any]:
        """åˆ›å»ºæ¨¡æ‹Ÿå›¾è¡¨æ•°æ®"""
        return {
            'gmv_trend': {'2024-01': 800000, '2024-02': 850000, '2024-03': 820000, '2024-04': 880000},
            'dau_trend': {'åŒ—äº¬': 1200, 'ä¸Šæµ·': 1100, 'å¹¿å·': 950, 'æ·±åœ³': 1050},
            'category_analysis': {'ç”µå­äº§å“': 35, 'æœè£…': 25, 'å®¶å±…': 20, 'å…¶ä»–': 20},
            'region_analysis': {'åŒ—äº¬': 1200, 'ä¸Šæµ·': 1100, 'å¹¿å·': 950, 'æ·±åœ³': 1050},
            'forecast': {
                '2024-05-01': {'actual': 880000, 'predicted': 885000},
                '2024-05-02': {'actual': 875000, 'predicted': 880000},
                '2024-05-03': {'actual': None, 'predicted': 890000}
            }
        }
    
    def _create_mock_data(self) -> Dict[str, Any]:
        """åˆ›å»ºæ¨¡æ‹Ÿä¸šåŠ¡æ•°æ®"""
        return {
            'total_gmv': 8500000,
            'total_dau': 4300,
            'conversion_rate': 3.2,
            'regions': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'],
            'categories': ['ç”µå­äº§å“', 'æœè£…', 'å®¶å±…', 'å…¶ä»–']
        }
    
    def _create_mock_analysis_results(self) -> Dict[str, Any]:
        """åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ"""
        return {
            'trend_analysis': {
                'gmv_trend': 'increasing',
                'growth_rate': 12.5
            },
            'segmentation': {
                'segments_count': 4,
                'largest_segment': 'segment_1'
            },
            'charts': {
                'charts_created': ['dashboard', 'heatmap', 'funnel'],
                'interactive_charts': ['dashboard.html']
            }
        }
    
    def _generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report_data = {
            'test_summary': {
                'total_tests': self.test_results['total_tests'],
                'passed_tests': self.test_results['passed_tests'],
                'failed_tests': self.test_results['failed_tests'],
                'pass_rate': (self.test_results['passed_tests'] / self.test_results['total_tests'] * 100) if self.test_results['total_tests'] > 0 else 0,
                'start_time': self.test_results['start_time'].isoformat(),
                'end_time': self.test_results['end_time'].isoformat(),
                'duration': (self.test_results['end_time'] - self.test_results['start_time']).total_seconds()
            },
            'test_details': self.test_results['test_details'],
            'performance_metrics': self.test_results['performance_metrics']
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_file = os.path.join(self.output_dir, f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_file = os.path.join(self.output_dir, f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
        self._generate_html_test_report(report_data, html_file)
        
        print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {json_file}")
        print(f"ğŸŒ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")
    
    def _generate_html_test_report(self, report_data: Dict[str, Any], filename: str):
        """ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š"""
        summary = report_data['test_summary']
        
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç»¼åˆæµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; border-bottom: 3px solid #007bff; padding-bottom: 20px; margin-bottom: 30px; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
        .metric {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }}
        .pass {{ color: #28a745; }}
        .fail {{ color: #dc3545; }}
        .test-item {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007bff; }}
        .performance {{ background: #e9ecef; padding: 20px; border-radius: 8px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ§ª ç»¼åˆæµ‹è¯•æŠ¥å‘Š</h1>
            <p>ç³»ç»ŸåŠŸèƒ½éªŒè¯ä¸æ€§èƒ½è¯„ä¼°</p>
        </div>
        
        <div class="summary">
            <div class="metric">
                <h3>æ€»æµ‹è¯•æ•°</h3>
                <div style="font-size: 2rem; font-weight: bold;">{summary['total_tests']}</div>
            </div>
            <div class="metric">
                <h3>é€šè¿‡æµ‹è¯•</h3>
                <div style="font-size: 2rem; font-weight: bold;">{summary['passed_tests']}</div>
            </div>
            <div class="metric">
                <h3>å¤±è´¥æµ‹è¯•</h3>
                <div style="font-size: 2rem; font-weight: bold;">{summary['failed_tests']}</div>
            </div>
            <div class="metric">
                <h3>é€šè¿‡ç‡</h3>
                <div style="font-size: 2rem; font-weight: bold;">{summary['pass_rate']:.1f}%</div>
            </div>
        </div>
        
        <h2>ğŸ“Š æµ‹è¯•è¯¦æƒ…</h2>
"""
        
        for test in report_data['test_details']:
            status_class = 'pass' if test['status'] == 'PASS' else 'fail'
            status_icon = 'âœ…' if test['status'] == 'PASS' else 'âŒ'
            
            html_content += f"""
        <div class="test-item">
            <strong class="{status_class}">{status_icon} {test['name']}</strong>
            <div>çŠ¶æ€: {test['status']}</div>
            {f"<div>é”™è¯¯: {test.get('error', '')}</div>" if test['status'] == 'FAIL' else ''}
            {f"<div>è€—æ—¶: {test.get('duration', 0):.3f}s</div>" if 'duration' in test else ''}
        </div>
"""
        
        html_content += f"""
        <h2>âš¡ æ€§èƒ½æŒ‡æ ‡</h2>
        <div class="performance">
"""
        
        for metric, value in report_data['performance_metrics'].items():
            if isinstance(value, dict):
                html_content += f"<h4>{metric}:</h4><ul>"
                for k, v in value.items():
                    html_content += f"<li>{k}: {v}</li>"
                html_content += "</ul>"
            else:
                html_content += f"<p><strong>{metric}:</strong> {value}</p>"
        
        html_content += f"""
        </div>
        
        <div style="text-align: center; margin-top: 40px; color: #6c757d;">
            <p>ğŸ¤– æµ‹è¯•å®Œæˆæ—¶é—´: {summary['end_time']}</p>
            <p>â±ï¸ æ€»è€—æ—¶: {summary['duration']:.2f}ç§’</p>
        </div>
    </div>
</body>
</html>
"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _display_test_summary(self):
        """æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦"""
        duration = (self.test_results['end_time'] - self.test_results['start_time']).total_seconds()
        pass_rate = (self.test_results['passed_tests'] / self.test_results['total_tests'] * 100) if self.test_results['total_tests'] > 0 else 0
        
        print("\n" + "=" * 80)
        print("ğŸ† æµ‹è¯•æ‘˜è¦")
        print("=" * 80)
        print(f"ğŸ“Š æ€»æµ‹è¯•æ•°: {self.test_results['total_tests']}")
        print(f"âœ… é€šè¿‡æµ‹è¯•: {self.test_results['passed_tests']}")
        print(f"âŒ å¤±è´¥æµ‹è¯•: {self.test_results['failed_tests']}")
        print(f"ğŸ“ˆ é€šè¿‡ç‡: {pass_rate:.1f}%")
        print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f}ç§’")
        
        if pass_rate >= 90:
            print("ğŸŒŸ æµ‹è¯•ç»“æœ: ä¼˜ç§€")
        elif pass_rate >= 80:
            print("ğŸ‘ æµ‹è¯•ç»“æœ: è‰¯å¥½")
        elif pass_rate >= 70:
            print("â¡ï¸ æµ‹è¯•ç»“æœ: ä¸€èˆ¬")
        else:
            print("âš ï¸ æµ‹è¯•ç»“æœ: éœ€è¦æ”¹è¿›")
        
        # æ˜¾ç¤ºç³»ç»Ÿç­‰çº§
        system_level = self.test_results['performance_metrics'].get('system_level', 'æœªçŸ¥')
        print(f"ğŸ† ç³»ç»ŸåŠŸèƒ½ç­‰çº§: {system_level}")
        
        print("=" * 80)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ä¸šåŠ¡åˆ†ææŠ¥å‘Šè‡ªåŠ¨åŒ–ç³»ç»Ÿ - ç»¼åˆæµ‹è¯•")
    print("ç‰ˆæœ¬: 3.0 Enhanced")
    print("=" * 80)
    
    # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•å¥—ä»¶
    test_suite = ComprehensiveTestSuite()
    results = test_suite.run_all_tests()
    
    return results


if __name__ == "__main__":
    main() 