#!/usr/bin/env python3
"""
è¾¹ç•Œæ¡ä»¶æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§è¾¹ç•Œæƒ…å†µä¸‹çš„è¡Œä¸º
"""

import pytest
import json
import os
import tempfile
import shutil
from datetime import datetime, timedelta
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.web_interface import WebInterface
from src.data.data_processor import DataProcessor
from src.analysis.professional_analytics import ProfessionalAnalytics
from src.visualization.chart_generator import ChartGenerator
from src.utils.logger import system_logger
from src.monitoring.metrics_collector import MetricsCollector
from src.security.encryption import DataEncryption
from src.security.audit_logger import SecurityAuditLogger


class TestBoundaryConditions:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
        self.test_data_dir = Path(self.temp_dir) / "test_data"
        self.test_output_dir = Path(self.temp_dir) / "test_output"
        
        self.test_data_dir.mkdir(exist_ok=True)
        self.test_output_dir.mkdir(exist_ok=True)
        
        yield
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_empty_data_processing(self, setup_test_environment):
        """æµ‹è¯•ç©ºæ•°æ®å¤„ç†"""
        processor = DataProcessor()
        
        # æµ‹è¯•ç©ºåˆ—è¡¨
        result = processor.process_data([])
        assert result is not None
        assert isinstance(result, dict)
        
        # æµ‹è¯•ç©ºå­—ç¬¦ä¸²
        result = processor.process_data("")
        assert result is not None
        
        # æµ‹è¯•Noneå€¼
        result = processor.process_data(None)
        assert result is not None
    
    def test_extremely_large_data(self, setup_test_environment):
        """æµ‹è¯•æå¤§æ•°æ®é‡å¤„ç†"""
        processor = DataProcessor()
        
        # ç”Ÿæˆå¤§é‡æ•°æ®
        large_data = []
        for i in range(10000):  # 1ä¸‡æ¡è®°å½•
            large_data.append({
                'id': i,
                'value': i * 1.5,
                'category': f'category_{i % 100}',
                'timestamp': datetime.now().isoformat()
            })
        
        # æµ‹è¯•å¤„ç†å¤§é‡æ•°æ®
        result = processor.process_data(large_data)
        assert result is not None
        assert 'processed_count' in result
        assert result['processed_count'] <= len(large_data)
    
    def test_malformed_data_handling(self, setup_test_environment):
        """æµ‹è¯•ç•¸å½¢æ•°æ®å¤„ç†"""
        processor = DataProcessor()
        
        # æµ‹è¯•å„ç§ç•¸å½¢æ•°æ®
        malformed_data = [
            {'incomplete': 'data'},  # ç¼ºå°‘å¿…è¦å­—æ®µ
            {'value': 'not_a_number'},  # é”™è¯¯çš„æ•°æ®ç±»å‹
            {'nested': {'deeply': {'nested': {'data': 'value'}}}},  # è¿‡åº¦åµŒå¥—
            {'special_chars': 'ç‰¹æ®Šå­—ç¬¦\n\t\r\x00'},  # ç‰¹æ®Šå­—ç¬¦
            {'unicode': 'ğŸš€ğŸ“ŠğŸ’»'},  # Unicodeå­—ç¬¦
            None,  # Noneå€¼
            '',  # ç©ºå­—ç¬¦ä¸²
            [],  # ç©ºåˆ—è¡¨
            {},  # ç©ºå­—å…¸
        ]
        
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†è€Œä¸å´©æºƒ
        result = processor.process_data(malformed_data)
        assert result is not None
    
    def test_memory_limits(self, setup_test_environment):
        """æµ‹è¯•å†…å­˜é™åˆ¶"""
        processor = DataProcessor()
        
        # åˆ›å»ºå ç”¨å¤§é‡å†…å­˜çš„æ•°æ®ç»“æ„
        memory_intensive_data = {
            'large_string': 'x' * (1024 * 1024),  # 1MBå­—ç¬¦ä¸²
            'large_list': list(range(100000)),  # 10ä¸‡ä¸ªæ•´æ•°
            'nested_structure': {
                f'key_{i}': {
                    'data': list(range(1000))
                } for i in range(100)
            }
        }
        
        # æµ‹è¯•æ˜¯å¦èƒ½å¤Ÿå¤„ç†å¤§å†…å­˜å ç”¨
        try:
            result = processor.process_data(memory_intensive_data)
            assert result is not None
        except MemoryError:
            # å¦‚æœå†…å­˜ä¸è¶³ï¼Œåº”è¯¥ä¼˜é›…åœ°å¤„ç†
            pytest.skip("Insufficient memory for this test")
    
    def test_file_system_limits(self, setup_test_environment):
        """æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿé™åˆ¶"""
        chart_generator = ChartGenerator()
        
        # æµ‹è¯•é•¿æ–‡ä»¶å
        long_filename = 'a' * 255  # æœ€å¤§æ–‡ä»¶åé•¿åº¦
        output_path = self.test_output_dir / f"{long_filename}.png"
        
        # æµ‹è¯•æ–‡ä»¶åè¿‡é•¿çš„æƒ…å†µ
        try:
            chart_generator.generate_chart(
                data={'x': [1, 2, 3], 'y': [1, 4, 9]},
                chart_type='line',
                output_path=str(output_path)
            )
        except OSError:
            # æ–‡ä»¶åè¿‡é•¿æ—¶åº”è¯¥ä¼˜é›…å¤„ç†
            pass
        
        # æµ‹è¯•æ— æ•ˆå­—ç¬¦
        invalid_filename = 'chart<>:"|?*.png'
        safe_filename = chart_generator._sanitize_filename(invalid_filename)
        assert '<' not in safe_filename
        assert '>' not in safe_filename
        assert '|' not in safe_filename
    
    def test_concurrent_access(self, setup_test_environment):
        """æµ‹è¯•å¹¶å‘è®¿é—®"""
        import threading
        import time
        
        results = []
        errors = []
        
        def worker():
            try:
                processor = DataProcessor()
                data = [{'id': i, 'value': i} for i in range(100)]
                result = processor.process_data(data)
                results.append(result)
            except Exception as e:
                errors.append(e)
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(10):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join(timeout=30)
        
        # æ£€æŸ¥ç»“æœ
        assert len(errors) == 0, f"Concurrent access errors: {errors}"
        assert len(results) > 0
    
    def test_network_timeout(self, setup_test_environment):
        """æµ‹è¯•ç½‘ç»œè¶…æ—¶"""
        with patch('requests.get') as mock_get:
            # æ¨¡æ‹Ÿç½‘ç»œè¶…æ—¶
            mock_get.side_effect = TimeoutError("Network timeout")
            
            # æµ‹è¯•ç½‘ç»œè¯·æ±‚è¶…æ—¶å¤„ç†
            from src.data.api_collector import APICollector
            collector = APICollector()
            
            result = collector.collect_data("http://example.com/api/data")
            # åº”è¯¥è¿”å›ç©ºç»“æœè€Œä¸æ˜¯å´©æºƒ
            assert result is not None
    
    def test_database_connection_failure(self, setup_test_environment):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥å¤±è´¥"""
        with patch('psycopg2.connect') as mock_connect:
            # æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥å¤±è´¥
            mock_connect.side_effect = Exception("Database connection failed")
            
            from src.data.database_collector import DatabaseCollector
            collector = DatabaseCollector()
            
            # åº”è¯¥ä¼˜é›…åœ°å¤„ç†è¿æ¥å¤±è´¥
            result = collector.collect_data("SELECT * FROM test_table")
            assert result is not None
    
    def test_disk_space_exhaustion(self, setup_test_environment):
        """æµ‹è¯•ç£ç›˜ç©ºé—´è€—å°½"""
        with patch('builtins.open', side_effect=OSError("No space left on device")):
            chart_generator = ChartGenerator()
            
            # æµ‹è¯•ç£ç›˜ç©ºé—´ä¸è¶³æ—¶çš„å¤„ç†
            result = chart_generator.generate_chart(
                data={'x': [1, 2, 3], 'y': [1, 4, 9]},
                chart_type='line',
                output_path=str(self.test_output_dir / "test.png")
            )
            
            # åº”è¯¥è¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯å´©æºƒ
            assert result is not None
    
    def test_unicode_handling(self, setup_test_environment):
        """æµ‹è¯•Unicodeå¤„ç†"""
        processor = DataProcessor()
        
        unicode_data = [
            {'name': 'å¼ ä¸‰', 'value': 100},
            {'name': 'JosÃ©', 'value': 200},
            {'name': 'MÃ¼ller', 'value': 300},
            {'name': 'ğŸš€ Rocket', 'value': 400},
            {'name': '\u200b\u200c\u200d', 'value': 500},  # é›¶å®½å­—ç¬¦
            {'name': '\x00\x01\x02', 'value': 600},  # æ§åˆ¶å­—ç¬¦
        ]
        
        result = processor.process_data(unicode_data)
        assert result is not None
        assert 'processed_count' in result
    
    def test_timezone_handling(self, setup_test_environment):
        """æµ‹è¯•æ—¶åŒºå¤„ç†"""
        analytics = ProfessionalAnalytics()
        
        # ä¸åŒæ—¶åŒºçš„æ—¶é—´æˆ³
        timezone_data = [
            {'timestamp': '2025-08-18T10:00:00+00:00', 'value': 100},
            {'timestamp': '2025-08-18T10:00:00+08:00', 'value': 200},
            {'timestamp': '2025-08-18T10:00:00-05:00', 'value': 300},
            {'timestamp': '2025-08-18T10:00:00Z', 'value': 400},
            {'timestamp': '2025-08-18 10:00:00', 'value': 500},  # æ— æ—¶åŒºä¿¡æ¯
        ]
        
        result = analytics.analyze_data(timezone_data)
        assert result is not None
    
    def test_floating_point_precision(self, setup_test_environment):
        """æµ‹è¯•æµ®ç‚¹æ•°ç²¾åº¦"""
        processor = DataProcessor()
        
        # æµ®ç‚¹æ•°ç²¾åº¦æµ‹è¯•æ•°æ®
        precision_data = [
            {'value': 0.1 + 0.2},  # åº”è¯¥æ˜¯0.3ï¼Œä½†å¯èƒ½æœ‰ç²¾åº¦è¯¯å·®
            {'value': 1e-10},  # æå°æ•°
            {'value': 1e10},   # æå¤§æ•°
            {'value': float('inf')},  # æ— ç©·å¤§
            {'value': float('-inf')}, # è´Ÿæ— ç©·å¤§
            {'value': float('nan')},  # NaN
        ]
        
        result = processor.process_data(precision_data)
        assert result is not None
    
    def test_date_boundary_conditions(self, setup_test_environment):
        """æµ‹è¯•æ—¥æœŸè¾¹ç•Œæ¡ä»¶"""
        analytics = ProfessionalAnalytics()
        
        # è¾¹ç•Œæ—¥æœŸæµ‹è¯•
        boundary_dates = [
            {'date': '1970-01-01', 'value': 100},  # Unixçºªå…ƒ
            {'date': '2038-01-19', 'value': 200},  # 32ä½æ—¶é—´æˆ³ä¸Šé™
            {'date': '2000-02-29', 'value': 300},  # é—°å¹´2æœˆ29æ—¥
            {'date': '1900-02-28', 'value': 400},  # éé—°å¹´
            {'date': '9999-12-31', 'value': 500},  # æœ€å¤§æ—¥æœŸ
            {'date': '0001-01-01', 'value': 600},  # æœ€å°æ—¥æœŸ
            {'date': 'invalid-date', 'value': 700}, # æ— æ•ˆæ—¥æœŸ
        ]
        
        result = analytics.analyze_data(boundary_dates)
        assert result is not None
    
    def test_encryption_edge_cases(self, setup_test_environment):
        """æµ‹è¯•åŠ å¯†è¾¹ç•Œæƒ…å†µ"""
        encryption = DataEncryption()
        
        # æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ
        test_cases = [
            "",  # ç©ºå­—ç¬¦ä¸²
            "a",  # å•å­—ç¬¦
            "a" * 10000,  # é•¿å­—ç¬¦ä¸²
            "\x00\x01\x02",  # äºŒè¿›åˆ¶æ•°æ®
            "ğŸš€ğŸ“ŠğŸ’»",  # Unicode
            None,  # Noneå€¼
            123,  # æ•°å­—
            [1, 2, 3],  # åˆ—è¡¨
            {'key': 'value'},  # å­—å…¸
        ]
        
        for test_data in test_cases:
            try:
                encrypted = encryption.encrypt_data(test_data)
                if encrypted is not None:
                    decrypted = encryption.decrypt_data(encrypted)
                    # å¯¹äºå¯åºåˆ—åŒ–çš„æ•°æ®ï¼Œåº”è¯¥èƒ½å¤Ÿæ­£ç¡®è§£å¯†
                    if isinstance(test_data, (str, dict, list)):
                        assert decrypted is not None
            except Exception as e:
                # è®°å½•ä½†ä¸å¤±è´¥ï¼ŒæŸäº›ç±»å‹å¯èƒ½ä¸æ”¯æŒåŠ å¯†
                system_logger.warning(f"Encryption test failed for {type(test_data)}: {e}")
    
    def test_metrics_collection_limits(self, setup_test_environment):
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†é™åˆ¶"""
        collector = MetricsCollector(collection_interval=1)
        
        # æµ‹è¯•å¿«é€Ÿè¿ç»­è°ƒç”¨
        for i in range(1000):
            collector.record_api_request(f"endpoint_{i}")
            collector.record_processing_time(0.1)
        
        # åº”è¯¥ä¸ä¼šå´©æºƒæˆ–æ¶ˆè€—è¿‡å¤šå†…å­˜
        summary = collector.get_metrics_summary()
        assert summary is not None
        assert 'total_metrics' in summary
    
    def test_audit_log_volume(self, setup_test_environment):
        """æµ‹è¯•å®¡è®¡æ—¥å¿—å¤§é‡å†™å…¥"""
        audit_logger = SecurityAuditLogger()
        
        # å¿«é€Ÿç”Ÿæˆå¤§é‡å®¡è®¡äº‹ä»¶
        for i in range(1000):
            audit_logger.log_api_call(
                user_id=f"user_{i % 10}",
                endpoint=f"/api/endpoint_{i % 50}",
                method="GET",
                status_code=200,
                ip_address=f"192.168.1.{i % 255}"
            )
        
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æ­£å¸¸
        stats = audit_logger.get_stats()
        assert stats is not None
        assert stats['total_events'] > 0
    
    def test_web_interface_stress(self, setup_test_environment):
        """æµ‹è¯•Webç•Œé¢å‹åŠ›"""
        web_interface = WebInterface()
        
        # æ¨¡æ‹Ÿå¤§é‡å¹¶å‘è¯·æ±‚
        import asyncio
        
        async def make_request():
            # æ¨¡æ‹Ÿå¤„ç†è¯·æ±‚
            await asyncio.sleep(0.01)
            return {'status': 'ok'}
        
        async def stress_test():
            tasks = [make_request() for _ in range(100)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            return results
        
        # è¿è¡Œå‹åŠ›æµ‹è¯•
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            results = loop.run_until_complete(stress_test())
            assert len(results) == 100
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
            exceptions = [r for r in results if isinstance(r, Exception)]
            assert len(exceptions) == 0, f"Found exceptions: {exceptions}"
        finally:
            loop.close()
    
    def test_configuration_edge_cases(self, setup_test_environment):
        """æµ‹è¯•é…ç½®è¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•ç©ºé…ç½®
        empty_config = {}
        
        # æµ‹è¯•æ— æ•ˆé…ç½®å€¼
        invalid_config = {
            'timeout': -1,
            'max_connections': 0,
            'buffer_size': 'invalid',
            'debug': 'not_boolean',
        }
        
        # æµ‹è¯•æç«¯é…ç½®å€¼
        extreme_config = {
            'timeout': 999999,
            'max_connections': 1000000,
            'buffer_size': 0,
            'batch_size': 1,
        }
        
        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†è¿™äº›é…ç½®è€Œä¸å´©æºƒ
        for config in [empty_config, invalid_config, extreme_config]:
            try:
                # è¿™é‡Œåº”è¯¥æµ‹è¯•å…·ä½“çš„é…ç½®åŠ è½½é€»è¾‘
                # æš‚æ—¶åªéªŒè¯é…ç½®ä¸ä¼šå¯¼è‡´å´©æºƒ
                assert isinstance(config, dict)
            except Exception as e:
                pytest.fail(f"Configuration handling failed: {e}")
    
    def test_error_recovery(self, setup_test_environment):
        """æµ‹è¯•é”™è¯¯æ¢å¤"""
        processor = DataProcessor()
        
        # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯
        def failing_process(data):
            if len(data) > 5:
                raise ValueError("Simulated processing error")
            return {'processed': True}
        
        # æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶
        test_data = [
            [1, 2, 3],  # æˆåŠŸ
            [1, 2, 3, 4, 5, 6, 7],  # å¤±è´¥
            [1, 2],  # æˆåŠŸ
        ]
        
        results = []
        for data in test_data:
            try:
                result = failing_process(data)
                results.append(result)
            except ValueError:
                # é”™è¯¯æ¢å¤ï¼šè®°å½•é”™è¯¯å¹¶ç»§ç»­
                results.append({'error': 'processing_failed'})
        
        assert len(results) == 3
        assert results[0]['processed'] is True
        assert 'error' in results[1]
        assert results[2]['processed'] is True


if __name__ == '__main__':
    pytest.main([__file__, '-v'])