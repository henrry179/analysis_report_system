#!/usr/bin/env python3
"""
SQLä»£ç ç®¡ç†å™¨
æ”¯æŒæœ¬åœ°SQLæ–‡ä»¶ç¼–å†™ã€æ‰§è¡Œã€ç®¡ç†å’Œä¸ªæ€§åŒ–æ•°æ®é›†å¯¼å…¥
"""

import os
import sys
import json
import logging
import sqlite3
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
import pandas as pd
from pathlib import Path
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.config.database_config import DatabaseConfig
from src.data.mysql_manager import MySQLManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SQLManager:
    """SQLä»£ç ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–SQLç®¡ç†å™¨
        
        Args:
            config: æ•°æ®åº“é…ç½®
        """
        self.config = config
        self.mysql_manager = None
        self.sql_files_dir = "sql_scripts"
        self.datasets_dir = "custom_datasets"
        self.templates_dir = "sql_templates"
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._create_directories()
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        if config:
            self._init_database_connection()
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
        directories = [
            self.sql_files_dir,
            f"{self.sql_files_dir}/queries",
            f"{self.sql_files_dir}/schema",
            f"{self.sql_files_dir}/procedures",
            f"{self.sql_files_dir}/functions",
            self.datasets_dir,
            f"{self.datasets_dir}/csv",
            f"{self.datasets_dir}/json",
            f"{self.datasets_dir}/excel",
            self.templates_dir
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
        
        logger.info("âœ… SQLç®¡ç†å™¨ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")
    
    def _init_database_connection(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            self.mysql_manager = MySQLManager(self.config)
            if self.mysql_manager.setup_database():
                logger.info("âœ… æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš ï¸ æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ¨¡å¼")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def create_sql_file(self, filename: str, content: str, file_type: str = "queries") -> bool:
        """
        åˆ›å»ºSQLæ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶å
            content: SQLå†…å®¹
            file_type: æ–‡ä»¶ç±»å‹ (queries, schema, procedures, functions)
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        try:
            if not filename.endswith('.sql'):
                filename += '.sql'
            
            file_path = os.path.join(self.sql_files_dir, file_type, filename)
            
            # æ·»åŠ æ–‡ä»¶å¤´æ³¨é‡Š
            header = f"""-- SQLæ–‡ä»¶: {filename}
-- åˆ›å»ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- æ–‡ä»¶ç±»å‹: {file_type}
-- æè¿°: ä¸ªæ€§åŒ–SQLä»£ç æ–‡ä»¶

"""
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(header + content)
            
            logger.info(f"âœ… SQLæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ SQLæ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(e)}")
            return False
    
    def list_sql_files(self, file_type: str = None) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºSQLæ–‡ä»¶
        
        Args:
            file_type: æ–‡ä»¶ç±»å‹ç­›é€‰
            
        Returns:
            List[Dict]: SQLæ–‡ä»¶åˆ—è¡¨
        """
        sql_files = []
        
        try:
            if file_type:
                search_dirs = [os.path.join(self.sql_files_dir, file_type)]
            else:
                search_dirs = [
                    os.path.join(self.sql_files_dir, "queries"),
                    os.path.join(self.sql_files_dir, "schema"),
                    os.path.join(self.sql_files_dir, "procedures"),
                    os.path.join(self.sql_files_dir, "functions")
                ]
            
            for search_dir in search_dirs:
                if os.path.exists(search_dir):
                    for file in os.listdir(search_dir):
                        if file.endswith('.sql'):
                            file_path = os.path.join(search_dir, file)
                            file_stat = os.stat(file_path)
                            
                            sql_files.append({
                                'filename': file,
                                'path': file_path,
                                'type': os.path.basename(search_dir),
                                'size': file_stat.st_size,
                                'created': datetime.fromtimestamp(file_stat.st_ctime),
                                'modified': datetime.fromtimestamp(file_stat.st_mtime)
                            })
            
            return sorted(sql_files, key=lambda x: x['modified'], reverse=True)
            
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºSQLæ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def read_sql_file(self, filename: str, file_type: str = "queries") -> Optional[str]:
        """
        è¯»å–SQLæ–‡ä»¶å†…å®¹
        
        Args:
            filename: æ–‡ä»¶å
            file_type: æ–‡ä»¶ç±»å‹
            
        Returns:
            str: SQLæ–‡ä»¶å†…å®¹
        """
        try:
            if not filename.endswith('.sql'):
                filename += '.sql'
            
            file_path = os.path.join(self.sql_files_dir, file_type, filename)
            
            if not os.path.exists(file_path):
                logger.error(f"âŒ SQLæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"âœ… SQLæ–‡ä»¶è¯»å–æˆåŠŸ: {file_path}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ SQLæ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
            return None
    
    def execute_sql_file(self, filename: str, file_type: str = "queries", 
                        params: Dict[str, Any] = None) -> Tuple[bool, Any]:
        """
        æ‰§è¡ŒSQLæ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶å
            file_type: æ–‡ä»¶ç±»å‹
            params: SQLå‚æ•°
            
        Returns:
            Tuple[bool, Any]: (æ˜¯å¦æˆåŠŸ, ç»“æœæ•°æ®)
        """
        try:
            # è¯»å–SQLæ–‡ä»¶
            sql_content = self.read_sql_file(filename, file_type)
            if not sql_content:
                return False, "SQLæ–‡ä»¶è¯»å–å¤±è´¥"
            
            # æ‰§è¡ŒSQL
            return self.execute_sql(sql_content, params)
            
        except Exception as e:
            logger.error(f"âŒ SQLæ–‡ä»¶æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False, str(e)
    
    def execute_sql(self, sql_content: str, params: Dict[str, Any] = None) -> Tuple[bool, Any]:
        """
        æ‰§è¡ŒSQLè¯­å¥
        
        Args:
            sql_content: SQLå†…å®¹
            params: SQLå‚æ•°
            
        Returns:
            Tuple[bool, Any]: (æ˜¯å¦æˆåŠŸ, ç»“æœæ•°æ®)
        """
        try:
            if not self.mysql_manager:
                return False, "æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–"
            
            # æ¸…ç†SQLè¯­å¥
            sql_statements = self._split_sql_statements(sql_content)
            
            results = []
            engine = self.mysql_manager.db_config.engine
            
            for sql in sql_statements:
                if sql.strip():
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæŸ¥è¯¢è¯­å¥
                    if sql.strip().upper().startswith('SELECT'):
                        # æ‰§è¡ŒæŸ¥è¯¢
                        df = pd.read_sql(sql, engine, params=params)
                        results.append({
                            'type': 'query',
                            'sql': sql,
                            'data': df,
                            'rows': len(df)
                        })
                    else:
                        # æ‰§è¡Œå…¶ä»–è¯­å¥
                        with engine.connect() as conn:
                            result = conn.execute(sql, params or {})
                            conn.commit()
                            results.append({
                                'type': 'execute',
                                'sql': sql,
                                'affected_rows': result.rowcount if hasattr(result, 'rowcount') else 0
                            })
            
            logger.info(f"âœ… SQLæ‰§è¡ŒæˆåŠŸï¼Œå…±æ‰§è¡Œ {len(results)} æ¡è¯­å¥")
            return True, results
            
        except Exception as e:
            logger.error(f"âŒ SQLæ‰§è¡Œå¤±è´¥: {str(e)}")
            return False, str(e)
    
    def _split_sql_statements(self, sql_content: str) -> List[str]:
        """
        åˆ†å‰²SQLè¯­å¥
        
        Args:
            sql_content: SQLå†…å®¹
            
        Returns:
            List[str]: SQLè¯­å¥åˆ—è¡¨
        """
        # ç§»é™¤æ³¨é‡Š
        sql_content = re.sub(r'--.*?\n', '\n', sql_content)
        sql_content = re.sub(r'/\*.*?\*/', '', sql_content, flags=re.DOTALL)
        
        # æŒ‰åˆ†å·åˆ†å‰²
        statements = [stmt.strip() for stmt in sql_content.split(';') if stmt.strip()]
        
        return statements
    
    def create_dataset_template(self, template_name: str, table_structure: Dict[str, Any]) -> bool:
        """
        åˆ›å»ºæ•°æ®é›†æ¨¡æ¿
        
        Args:
            template_name: æ¨¡æ¿åç§°
            table_structure: è¡¨ç»“æ„å®šä¹‰
            
        Returns:
            bool: åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        try:
            template_file = os.path.join(self.templates_dir, f"{template_name}.json")
            
            template_data = {
                'name': template_name,
                'created_at': datetime.now().isoformat(),
                'description': f"ä¸ªæ€§åŒ–æ•°æ®é›†æ¨¡æ¿: {template_name}",
                'structure': table_structure,
                'sample_data': self._generate_sample_data(table_structure)
            }
            
            with open(template_file, 'w', encoding='utf-8') as f:
                json.dump(template_data, f, ensure_ascii=False, indent=2)
            
            # åˆ›å»ºå¯¹åº”çš„SQLå»ºè¡¨è¯­å¥
            sql_content = self._generate_create_table_sql(template_name, table_structure)
            self.create_sql_file(f"create_{template_name}_table.sql", sql_content, "schema")
            
            logger.info(f"âœ… æ•°æ®é›†æ¨¡æ¿åˆ›å»ºæˆåŠŸ: {template_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®é›†æ¨¡æ¿åˆ›å»ºå¤±è´¥: {str(e)}")
            return False
    
    def _generate_sample_data(self, table_structure: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆç¤ºä¾‹æ•°æ®
        
        Args:
            table_structure: è¡¨ç»“æ„
            
        Returns:
            List[Dict]: ç¤ºä¾‹æ•°æ®
        """
        sample_data = []
        
        for i in range(3):  # ç”Ÿæˆ3æ¡ç¤ºä¾‹æ•°æ®
            row = {}
            for column, column_info in table_structure.items():
                column_type = column_info.get('type', 'VARCHAR').upper()
                
                if 'INT' in column_type:
                    row[column] = i + 1
                elif 'FLOAT' in column_type or 'DECIMAL' in column_type:
                    row[column] = round((i + 1) * 10.5, 2)
                elif 'DATE' in column_type:
                    row[column] = f"2024-01-{i+1:02d}"
                elif 'DATETIME' in column_type or 'TIMESTAMP' in column_type:
                    row[column] = f"2024-01-{i+1:02d} 10:00:00"
                else:
                    row[column] = f"ç¤ºä¾‹æ•°æ®_{i+1}"
            
            sample_data.append(row)
        
        return sample_data
    
    def _generate_create_table_sql(self, table_name: str, table_structure: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆå»ºè¡¨SQLè¯­å¥
        
        Args:
            table_name: è¡¨å
            table_structure: è¡¨ç»“æ„
            
        Returns:
            str: å»ºè¡¨SQL
        """
        sql_lines = [f"CREATE TABLE IF NOT EXISTS {table_name} ("]
        
        columns = []
        for column, column_info in table_structure.items():
            column_type = column_info.get('type', 'VARCHAR(255)')
            nullable = '' if column_info.get('nullable', True) else ' NOT NULL'
            default = f" DEFAULT '{column_info['default']}'" if 'default' in column_info else ''
            comment = f" COMMENT '{column_info['comment']}'" if 'comment' in column_info else ''
            
            column_def = f"  {column} {column_type}{nullable}{default}{comment}"
            columns.append(column_def)
        
        sql_lines.append(',\n'.join(columns))
        sql_lines.append(") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ä¸ªæ€§åŒ–æ•°æ®è¡¨';")
        
        return '\n'.join(sql_lines)
    
    def import_custom_dataset(self, file_path: str, table_name: str, 
                             mapping: Dict[str, str] = None) -> bool:
        """
        å¯¼å…¥ä¸ªæ€§åŒ–æ•°æ®é›†
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            table_name: ç›®æ ‡è¡¨å
            mapping: å­—æ®µæ˜ å°„å…³ç³»
            
        Returns:
            bool: å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æµ‹æ–‡ä»¶ç±»å‹å¹¶è¯»å–æ•°æ®
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext == '.csv':
                df = pd.read_csv(file_path, encoding='utf-8')
            elif file_ext == '.json':
                df = pd.read_json(file_path)
            elif file_ext in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
            else:
                logger.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                return False
            
            # åº”ç”¨å­—æ®µæ˜ å°„
            if mapping:
                df = df.rename(columns=mapping)
            
            # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
            df = self._preprocess_dataframe(df)
            
            # å¯¼å…¥åˆ°æ•°æ®åº“
            if self.mysql_manager:
                engine = self.mysql_manager.db_config.engine
                df.to_sql(table_name, engine, if_exists='append', index=False)
                logger.info(f"âœ… æ•°æ®å¯¼å…¥æˆåŠŸ: {len(df)} è¡Œæ•°æ®å¯¼å…¥åˆ°è¡¨ {table_name}")
            else:
                # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
                output_file = os.path.join(self.datasets_dir, f"{table_name}_imported.csv")
                df.to_csv(output_file, index=False, encoding='utf-8')
                logger.info(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {output_file}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")
            return False
    
    def _preprocess_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        é¢„å¤„ç†DataFrame
        
        Args:
            df: åŸå§‹DataFrame
            
        Returns:
            pd.DataFrame: é¢„å¤„ç†åçš„DataFrame
        """
        # å¤„ç†ç©ºå€¼
        df = df.fillna('')
        
        # å¤„ç†åˆ—åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
        df.columns = [re.sub(r'[^\w\u4e00-\u9fff]', '_', col) for col in df.columns]
        
        # æ·»åŠ å¯¼å…¥æ—¶é—´æˆ³
        df['imported_at'] = datetime.now()
        
        return df
    
    def generate_sql_templates(self):
        """ç”Ÿæˆå¸¸ç”¨SQLæ¨¡æ¿"""
        templates = {
            'basic_select.sql': """-- åŸºç¡€æŸ¥è¯¢æ¨¡æ¿
SELECT 
    column1,
    column2,
    COUNT(*) as count
FROM your_table_name
WHERE condition = 'value'
GROUP BY column1, column2
ORDER BY count DESC
LIMIT 10;""",
            
            'data_analysis.sql': """-- æ•°æ®åˆ†ææ¨¡æ¿
SELECT 
    DATE(date_column) as analysis_date,
    category,
    SUM(amount) as total_amount,
    AVG(amount) as avg_amount,
    COUNT(*) as record_count
FROM your_table_name
WHERE date_column >= '2024-01-01'
GROUP BY DATE(date_column), category
ORDER BY analysis_date DESC, total_amount DESC;""",
            
            'join_query.sql': """-- å…³è”æŸ¥è¯¢æ¨¡æ¿
SELECT 
    a.id,
    a.name,
    b.category,
    b.value
FROM table_a a
LEFT JOIN table_b b ON a.id = b.foreign_key
WHERE a.status = 'active'
ORDER BY a.name;""",
            
            'create_index.sql': """-- åˆ›å»ºç´¢å¼•æ¨¡æ¿
-- ä¸ºæé«˜æŸ¥è¯¢æ€§èƒ½åˆ›å»ºç´¢å¼•
CREATE INDEX idx_table_column ON your_table_name(column_name);
CREATE INDEX idx_table_multi ON your_table_name(column1, column2);""",
            
            'data_validation.sql': """-- æ•°æ®éªŒè¯æ¨¡æ¿
-- æ£€æŸ¥æ•°æ®è´¨é‡
SELECT 
    'total_records' as metric,
    COUNT(*) as value
FROM your_table_name

UNION ALL

SELECT 
    'null_values' as metric,
    COUNT(*) as value
FROM your_table_name
WHERE important_column IS NULL

UNION ALL

SELECT 
    'duplicate_records' as metric,
    COUNT(*) - COUNT(DISTINCT unique_column) as value
FROM your_table_name;"""
        }
        
        for filename, content in templates.items():
            self.create_sql_file(filename, content, "queries")
        
        logger.info("âœ… SQLæ¨¡æ¿ç”Ÿæˆå®Œæˆ")
    
    def export_query_results(self, sql_content: str, output_file: str, 
                           file_format: str = 'csv') -> bool:
        """
        å¯¼å‡ºæŸ¥è¯¢ç»“æœ
        
        Args:
            sql_content: SQLæŸ¥è¯¢è¯­å¥
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            file_format: è¾“å‡ºæ ¼å¼ (csv, json, excel)
            
        Returns:
            bool: å¯¼å‡ºæ˜¯å¦æˆåŠŸ
        """
        try:
            success, results = self.execute_sql(sql_content)
            
            if not success:
                logger.error(f"âŒ SQLæŸ¥è¯¢å¤±è´¥: {results}")
                return False
            
            # æ‰¾åˆ°æŸ¥è¯¢ç»“æœ
            query_result = None
            for result in results:
                if result['type'] == 'query' and 'data' in result:
                    query_result = result['data']
                    break
            
            if query_result is None:
                logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°æŸ¥è¯¢ç»“æœ")
                return False
            
            # å¯¼å‡ºæ•°æ®
            if file_format.lower() == 'csv':
                query_result.to_csv(output_file, index=False, encoding='utf-8')
            elif file_format.lower() == 'json':
                query_result.to_json(output_file, orient='records', ensure_ascii=False, indent=2)
            elif file_format.lower() in ['xlsx', 'excel']:
                query_result.to_excel(output_file, index=False)
            else:
                logger.error(f"âŒ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {file_format}")
                return False
            
            logger.info(f"âœ… æŸ¥è¯¢ç»“æœå¯¼å‡ºæˆåŠŸ: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢ç»“æœå¯¼å‡ºå¤±è´¥: {str(e)}")
            return False


def interactive_sql_manager():
    """äº¤äº’å¼SQLç®¡ç†å™¨"""
    print("ğŸ”§ SQLä»£ç ç®¡ç†å™¨")
    print("=" * 50)
    
    # è·å–æ•°æ®åº“é…ç½®
    config_file = input("MySQLé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: src/config/mysql_config.json): ") or "src/config/mysql_config.json"
    
    config = None
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if config.get('password') == '***':
            password = input("è¯·è¾“å…¥MySQLå¯†ç : ")
            config['password'] = password
    else:
        print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åœ¨æœ¬åœ°æ¨¡å¼ä¸‹è¿è¡Œ")
    
    # åˆ›å»ºSQLç®¡ç†å™¨
    sql_manager = SQLManager(config)
    
    # ç”ŸæˆSQLæ¨¡æ¿
    sql_manager.generate_sql_templates()
    
    while True:
        print("\nğŸ“‹ SQLç®¡ç†å™¨èœå•:")
        print("1. åˆ›å»ºSQLæ–‡ä»¶")
        print("2. åˆ—å‡ºSQLæ–‡ä»¶")
        print("3. æ‰§è¡ŒSQLæ–‡ä»¶")
        print("4. å¯¼å…¥ä¸ªæ€§åŒ–æ•°æ®é›†")
        print("5. åˆ›å»ºæ•°æ®é›†æ¨¡æ¿")
        print("6. å¯¼å‡ºæŸ¥è¯¢ç»“æœ")
        print("7. é€€å‡º")
        
        choice = input("è¯·é€‰æ‹©æ“ä½œ (1-7): ").strip()
        
        if choice == '1':
            # åˆ›å»ºSQLæ–‡ä»¶
            filename = input("SQLæ–‡ä»¶å: ")
            file_type = input("æ–‡ä»¶ç±»å‹ (queries/schema/procedures/functions): ") or "queries"
            print("è¯·è¾“å…¥SQLå†…å®¹ (è¾“å…¥'END'ç»“æŸ):")
            
            lines = []
            while True:
                line = input()
                if line.strip() == 'END':
                    break
                lines.append(line)
            
            content = '\n'.join(lines)
            sql_manager.create_sql_file(filename, content, file_type)
        
        elif choice == '2':
            # åˆ—å‡ºSQLæ–‡ä»¶
            files = sql_manager.list_sql_files()
            if files:
                print("\nğŸ“ SQLæ–‡ä»¶åˆ—è¡¨:")
                for file in files:
                    print(f"  - {file['filename']} ({file['type']}) - {file['modified']}")
            else:
                print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°SQLæ–‡ä»¶")
        
        elif choice == '3':
            # æ‰§è¡ŒSQLæ–‡ä»¶
            filename = input("SQLæ–‡ä»¶å: ")
            file_type = input("æ–‡ä»¶ç±»å‹ (queries/schema/procedures/functions): ") or "queries"
            
            success, results = sql_manager.execute_sql_file(filename, file_type)
            
            if success:
                print("âœ… SQLæ‰§è¡ŒæˆåŠŸ:")
                for result in results:
                    if result['type'] == 'query':
                        print(f"  æŸ¥è¯¢ç»“æœ: {result['rows']} è¡Œæ•°æ®")
                        print(result['data'].head())
                    else:
                        print(f"  æ‰§è¡Œç»“æœ: å½±å“ {result['affected_rows']} è¡Œ")
            else:
                print(f"âŒ SQLæ‰§è¡Œå¤±è´¥: {results}")
        
        elif choice == '4':
            # å¯¼å…¥ä¸ªæ€§åŒ–æ•°æ®é›†
            file_path = input("æ•°æ®æ–‡ä»¶è·¯å¾„: ")
            table_name = input("ç›®æ ‡è¡¨å: ")
            
            if sql_manager.import_custom_dataset(file_path, table_name):
                print("âœ… æ•°æ®å¯¼å…¥æˆåŠŸ")
            else:
                print("âŒ æ•°æ®å¯¼å…¥å¤±è´¥")
        
        elif choice == '5':
            # åˆ›å»ºæ•°æ®é›†æ¨¡æ¿
            template_name = input("æ¨¡æ¿åç§°: ")
            print("è¯·å®šä¹‰è¡¨ç»“æ„ (æ ¼å¼: åˆ—å:ç±»å‹:æ³¨é‡Šï¼Œè¾“å…¥'END'ç»“æŸ):")
            
            structure = {}
            while True:
                line = input().strip()
                if line == 'END':
                    break
                
                if ':' in line:
                    parts = line.split(':')
                    column_name = parts[0].strip()
                    column_type = parts[1].strip() if len(parts) > 1 else 'VARCHAR(255)'
                    comment = parts[2].strip() if len(parts) > 2 else ''
                    
                    structure[column_name] = {
                        'type': column_type,
                        'comment': comment,
                        'nullable': True
                    }
            
            if structure:
                sql_manager.create_dataset_template(template_name, structure)
                print("âœ… æ•°æ®é›†æ¨¡æ¿åˆ›å»ºæˆåŠŸ")
            else:
                print("âŒ è¡¨ç»“æ„å®šä¹‰ä¸ºç©º")
        
        elif choice == '6':
            # å¯¼å‡ºæŸ¥è¯¢ç»“æœ
            print("è¯·è¾“å…¥SQLæŸ¥è¯¢è¯­å¥ (è¾“å…¥'END'ç»“æŸ):")
            lines = []
            while True:
                line = input()
                if line.strip() == 'END':
                    break
                lines.append(line)
            
            sql_content = '\n'.join(lines)
            output_file = input("è¾“å‡ºæ–‡ä»¶è·¯å¾„: ")
            file_format = input("è¾“å‡ºæ ¼å¼ (csv/json/excel): ") or "csv"
            
            if sql_manager.export_query_results(sql_content, output_file, file_format):
                print("âœ… æŸ¥è¯¢ç»“æœå¯¼å‡ºæˆåŠŸ")
            else:
                print("âŒ æŸ¥è¯¢ç»“æœå¯¼å‡ºå¤±è´¥")
        
        elif choice == '7':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨SQLç®¡ç†å™¨")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")


if __name__ == "__main__":
    interactive_sql_manager()