# å¤§æ¨¡å‹è°ƒç”¨ç¼–ç¨‹è§„åˆ™ / Large Language Model API Calling Rules

> æœ¬æ–‡æ¡£æä¾›å„ç±»å¤§æ¨¡å‹APIè°ƒç”¨çš„æ ‡å‡†è§„èŒƒå’Œæœ€ä½³å®è·µ
> This document provides standard specifications and best practices for calling various large language model APIs

**æœ€åæ›´æ–° / Last updated: 2025å¹´09æœˆ02æ—¥ 11:09:34**

---

## ğŸ“‹ ç›®å½• / Table of Contents

- [æ¦‚è¿° / Overview](#æ¦‚è¿°--overview)
- [é€šç”¨è°ƒç”¨è§„åˆ™ / General Calling Rules](#é€šç”¨è°ƒç”¨è§„åˆ™--general-calling-rules)
- [OpenAI GPTç³»åˆ—è°ƒç”¨è§„åˆ™ / OpenAI GPT Series Calling Rules](#openai-gptç³»åˆ—è°ƒç”¨è§„åˆ™--openai-gpt-series-calling-rules)
- [Anthropic Claudeè°ƒç”¨è§„åˆ™ / Anthropic Claude Calling Rules](#anthropic-claudeè°ƒç”¨è§„åˆ™--anthropic-claude-calling-rules)
- [Google Geminiè°ƒç”¨è§„åˆ™ / Google Gemini Calling Rules](#google-geminiè°ƒç”¨è§„åˆ™--google-gemini-calling-rules)
- [å›½äº§æ¨¡å‹è°ƒç”¨è§„åˆ™ / Domestic Model Calling Rules](#å›½äº§æ¨¡å‹è°ƒç”¨è§„åˆ™--domestic-model-calling-rules)
- [é”™è¯¯å¤„ç†ç­–ç•¥ / Error Handling Strategies](#é”™è¯¯å¤„ç†ç­–ç•¥--error-handling-strategies)
- [æ€§èƒ½ä¼˜åŒ–æŠ€å·§ / Performance Optimization Techniques](#æ€§èƒ½ä¼˜åŒ–æŠ€å·§--performance-optimization-techniques)
- [å®‰å…¨å’Œåˆè§„è¦æ±‚ / Security and Compliance Requirements](#å®‰å…¨å’Œåˆè§„è¦æ±‚--security-and-compliance-requirements)

---

## æ¦‚è¿° / Overview

### è®¾è®¡ç›®æ ‡ / Design Goals

å¤§æ¨¡å‹è°ƒç”¨ç¼–ç¨‹è§„åˆ™æ—¨åœ¨æä¾›ç»Ÿä¸€çš„APIè°ƒç”¨æ ‡å‡†ï¼Œç¡®ä¿ï¼š
- **å¯é æ€§**: ç¨³å®šçš„æœåŠ¡è°ƒç”¨å’Œé”™è¯¯æ¢å¤
- **æ•ˆç‡**: ä¼˜åŒ–çš„æ€§èƒ½å’Œèµ„æºä½¿ç”¨
- **å®‰å…¨æ€§**: ä¿æŠ¤æ•°æ®å’ŒAPIå¯†é’¥å®‰å…¨
- **å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„ä»£ç ç»“æ„å’Œæ–‡æ¡£

The large language model calling programming rules aim to provide unified API calling standards to ensure:
- **Reliability**: Stable service calls and error recovery
- **Efficiency**: Optimized performance and resource usage
- **Security**: Protection of data and API key security
- **Maintainability**: Clear code structure and documentation

---

## é€šç”¨è°ƒç”¨è§„åˆ™ / General Calling Rules

### ğŸ”§ 1. APIå®¢æˆ·ç«¯æ¶æ„ / API Client Architecture

#### æ ‡å‡†åŒ–å®¢æˆ·ç«¯è®¾è®¡ / Standardized Client Design

```xml
<api_client_architecture>
  <client_structure>
    <!-- å®¢æˆ·ç«¯ç»“æ„ / Client structure -->
    <configuration_layer>é…ç½®å±‚ / Configuration layer</configuration_layer>
    <authentication_layer>è®¤è¯å±‚ / Authentication layer</authentication_layer>
    <request_layer>è¯·æ±‚å±‚ / Request layer</request_layer>
    <response_layer>å“åº”å±‚ / Response layer</response_layer>
    <error_handling_layer>é”™è¯¯å¤„ç†å±‚ / Error handling layer</error_handling_layer>
  </client_structure>

  <abstraction_requirements>
    <!-- æŠ½è±¡åŒ–è¦æ±‚ / Abstraction requirements -->
    <model_abstraction>æ¨¡å‹æŠ½è±¡ / Model abstraction</model_abstraction>
    <provider_abstraction>æä¾›å•†æŠ½è±¡ / Provider abstraction</provider_abstraction>
    <interface_unification>æ¥å£ç»Ÿä¸€ / Interface unification</interface_unification>
  </abstraction_requirements>
</api_client_architecture>
```

#### å®¢æˆ·ç«¯å®ç°ç¤ºä¾‹ / Client Implementation Example

```python
# ç»Ÿä¸€çš„APIå®¢æˆ·ç«¯æ¥å£ / Unified API client interface
class LLMClient(ABC):
    @abstractmethod
    async def chat_completion(self, messages: List[Dict], **kwargs) -> Dict:
        """ç»Ÿä¸€çš„èŠå¤©å®Œæˆæ¥å£ / Unified chat completion interface"""
        pass

    @abstractmethod
    async def stream_completion(self, messages: List[Dict], **kwargs) -> AsyncGenerator:
        """ç»Ÿä¸€çš„æµå¼å“åº”æ¥å£ / Unified streaming response interface"""
        pass
```

### ğŸ” 2. è®¤è¯å’Œæˆæƒ / Authentication and Authorization

#### APIå¯†é’¥ç®¡ç† / API Key Management

```xml
<authentication_management>
  <key_storage>
    <!-- å¯†é’¥å­˜å‚¨ç­–ç•¥ / Key storage strategy -->
    <environment_variables>ç¯å¢ƒå˜é‡å­˜å‚¨ / Environment variables</environment_variables>
    <secure_vaults>å®‰å…¨ä¿ç®¡åº“ / Secure vaults</secure_vaults>
    <key_rotation>å¯†é’¥è½®æ¢æœºåˆ¶ / Key rotation mechanism</key_rotation>
  </key_storage>

  <access_control>
    <!-- è®¿é—®æ§åˆ¶ / Access control -->
    <rate_limiting>é€Ÿç‡é™åˆ¶ / Rate limiting</rate_limiting>
    <quota_management>é…é¢ç®¡ç† / Quota management</quota_management>
    <usage_monitoring>ä½¿ç”¨ç›‘æ§ / Usage monitoring</usage_monitoring>
  </access_control>
</authentication_management>
```

#### å®‰å…¨æœ€ä½³å®è·µ / Security Best Practices

```python
# å®‰å…¨çš„APIå¯†é’¥ç®¡ç† / Secure API key management
class SecureAPIKeyManager:
    def __init__(self):
        self._keys = {}
        self._load_keys_from_secure_storage()

    def get_key(self, provider: str) -> str:
        """å®‰å…¨è·å–APIå¯†é’¥ / Securely get API key"""
        if provider not in self._keys:
            raise ValueError(f"API key for {provider} not found")
        return self._decrypt_key(self._keys[provider])

    def rotate_key(self, provider: str, new_key: str):
        """è½®æ¢APIå¯†é’¥ / Rotate API key"""
        self._validate_key_format(provider, new_key)
        encrypted_key = self._encrypt_key(new_key)
        self._keys[provider] = encrypted_key
        self._save_keys_to_secure_storage()
```

### ğŸ“Š 3. è¯·æ±‚æ„å»ºè§„èŒƒ / Request Construction Standards

#### æ¶ˆæ¯æ ¼å¼æ ‡å‡†åŒ– / Message Format Standardization

```xml
<message_formatting>
  <standard_structure>
    <!-- æ ‡å‡†æ¶ˆæ¯ç»“æ„ / Standard message structure -->
    <role_field>è§’è‰²å­—æ®µ / Role field</role_field>
    <content_field>å†…å®¹å­—æ®µ / Content field</content_field>
    <metadata_field>å…ƒæ•°æ®å­—æ®µ / Metadata field</metadata_field>
  </standard_structure>

  <content_types>
    <!-- å†…å®¹ç±»å‹ / Content types -->
    <text_content>æ–‡æœ¬å†…å®¹ / Text content</text_content>
    <multimodal_content>å¤šæ¨¡æ€å†…å®¹ / Multimodal content</multimodal_content>
    <structured_content>ç»“æ„åŒ–å†…å®¹ / Structured content</structured_content>
  </content_types>
</message_formatting>
```

#### è¯·æ±‚å‚æ•°éªŒè¯ / Request Parameter Validation

```python
# è¯·æ±‚å‚æ•°éªŒè¯å™¨ / Request parameter validator
class RequestValidator:
    @staticmethod
    def validate_messages(messages: List[Dict]) -> bool:
        """éªŒè¯æ¶ˆæ¯æ ¼å¼ / Validate message format"""
        if not isinstance(messages, list) or not messages:
            return False

        for msg in messages:
            if not isinstance(msg, dict):
                return False
            if 'role' not in msg or 'content' not in msg:
                return False
            if msg['role'] not in ['system', 'user', 'assistant']:
                return False
            if not isinstance(msg['content'], str) or not msg['content'].strip():
                return False
        return True

    @staticmethod
    def validate_parameters(**kwargs) -> Dict:
        """éªŒè¯å¹¶è§„èŒƒåŒ–å‚æ•° / Validate and normalize parameters"""
        validated = {}

        # æ¸©åº¦å‚æ•°éªŒè¯ / Temperature parameter validation
        if 'temperature' in kwargs:
            temp = kwargs['temperature']
            if not isinstance(temp, (int, float)) or not 0 <= temp <= 2:
                raise ValueError("Temperature must be between 0 and 2")
            validated['temperature'] = float(temp)

        # æœ€å¤§tokenéªŒè¯ / Max tokens validation
        if 'max_tokens' in kwargs:
            max_t = kwargs['max_tokens']
            if not isinstance(max_t, int) or max_t <= 0:
                raise ValueError("Max tokens must be a positive integer")
            validated['max_tokens'] = max_t

        return validated
```

---

## OpenAI GPTç³»åˆ—è°ƒç”¨è§„åˆ™ / OpenAI GPT Series Calling Rules

### ğŸ¯ 4. GPTæ¨¡å‹è°ƒç”¨è§„èŒƒ / GPT Model Calling Standards

#### æ¨¡å‹é€‰æ‹©ç­–ç•¥ / Model Selection Strategy

```xml
<gpt_model_selection>
  <model_mapping>
    <!-- æ¨¡å‹æ˜ å°„ / Model mapping -->
    <gpt-4-turbo>GPT-4 Turbo - å¤æ‚ä»»åŠ¡ / Complex tasks</gpt-4-turbo>
    <gpt-4>GPT-4 - é«˜è´¨é‡è¾“å‡º / High-quality output</gpt-4>
    <gpt-3.5-turbo>GPT-3.5 Turbo - å¿«é€Ÿå“åº” / Fast response</gpt-3.5-turbo>
  </model_mapping>

  <task_model_matching>
    <!-- ä»»åŠ¡æ¨¡å‹åŒ¹é… / Task-model matching -->
    <creative_tasks>åˆ›æ„ä»»åŠ¡ - GPT-4 / Creative tasks - GPT-4</creative_tasks>
    <analytical_tasks>åˆ†æä»»åŠ¡ - GPT-4 / Analytical tasks - GPT-4</analytical_tasks>
    <simple_tasks>ç®€å•ä»»åŠ¡ - GPT-3.5 / Simple tasks - GPT-3.5</simple_tasks>
  </task_model_matching>
</gpt_model_selection>
```

#### GPT-4æœ€ä½³å®è·µ / GPT-4 Best Practices

```python
# GPT-4è°ƒç”¨æœ€ä½³å®è·µ / GPT-4 calling best practices
class GPT4Client:
    async def optimized_completion(self, messages: List[Dict], task_type: str) -> Dict:
        """ä¼˜åŒ–çš„GPT-4è°ƒç”¨ / Optimized GPT-4 call"""
        # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´å‚æ•° / Adjust parameters based on task type
        params = self._get_task_specific_params(task_type)

        # ä½¿ç”¨JSONæ¨¡å¼è¿›è¡Œç»“æ„åŒ–è¾“å‡º / Use JSON mode for structured output
        if task_type in ['analysis', 'classification']:
            params['response_format'] = {'type': 'json_object'}

        # å¯ç”¨å¹¶è¡Œå‡½æ•°è°ƒç”¨ / Enable parallel function calling
        if task_type == 'multi_step':
            params['parallel_tool_calls'] = True

        response = await self._call_openai_api(messages, **params)
        return self._process_response(response)

    def _get_task_specific_params(self, task_type: str) -> Dict:
        """è·å–ä»»åŠ¡ç‰¹å®šå‚æ•° / Get task-specific parameters"""
        base_params = {
            'model': 'gpt-4-turbo-preview',
            'temperature': 0.7,
            'max_tokens': 2000
        }

        task_configs = {
            'creative': {'temperature': 0.9, 'max_tokens': 3000},
            'analytical': {'temperature': 0.1, 'max_tokens': 1500},
            'conversational': {'temperature': 0.7, 'max_tokens': 1000},
            'coding': {'temperature': 0.2, 'max_tokens': 4000}
        }

        return {**base_params, **task_configs.get(task_type, {})}
```

### ğŸ”„ 5. æµå¼å“åº”å¤„ç† / Streaming Response Handling

#### æµå¼è°ƒç”¨å®ç° / Streaming Implementation

```python
# æµå¼å“åº”å¤„ç†å™¨ / Streaming response handler
class StreamingHandler:
    async def handle_streaming_response(self, response_stream):
        """å¤„ç†æµå¼å“åº” / Handle streaming response"""
        accumulated_content = ""
        last_chunk_time = time.time()

        async for chunk in response_stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                accumulated_content += content

                # å®æ—¶å¤„ç†å†…å®¹ / Process content in real-time
                await self._process_chunk(content)

                # æ£€æŸ¥å“åº”è¶…æ—¶ / Check for response timeout
                if time.time() - last_chunk_time > self.timeout_threshold:
                    await self._handle_timeout()
                    break

                last_chunk_time = time.time()

            # å¤„ç†å‡½æ•°è°ƒç”¨ / Handle function calls
            if chunk.choices[0].delta.tool_calls:
                await self._handle_tool_calls(chunk.choices[0].delta.tool_calls)

        return accumulated_content

    async def _process_chunk(self, content: str):
        """å¤„ç†å†…å®¹å— / Process content chunk"""
        # å®æ—¶è¯­æ³•æ£€æŸ¥ / Real-time syntax checking
        # å†…å®¹è¿‡æ»¤ / Content filtering
        # ç”¨æˆ·ç•Œé¢æ›´æ–° / UI updates
        pass
```

---

## Anthropic Claudeè°ƒç”¨è§„åˆ™ / Anthropic Claude Calling Rules

### ğŸ§  6. Claudeæ¨¡å‹ç‰¹æ€§ / Claude Model Characteristics

#### Claudeä¼˜åŠ¿å’Œåº”ç”¨åœºæ™¯ / Claude Advantages and Use Cases

```xml
<claude_model_characteristics>
  <strengths>
    <!-- Claudeä¼˜åŠ¿ / Claude strengths -->
    <long_context>é•¿ä¸Šä¸‹æ–‡ç†è§£ / Long context understanding</long_context>
    <ethical_reasoning>ä¼¦ç†æ¨ç†èƒ½åŠ› / Ethical reasoning ability</ethical_reasoning>
    <instruction_following>æŒ‡ä»¤éµå¾ªæ€§ / Instruction following</instruction_following>
  </strengths>

  <optimal_use_cases>
    <!-- æœ€ä¼˜åº”ç”¨åœºæ™¯ / Optimal use cases -->
    <complex_analysis>å¤æ‚åˆ†æä»»åŠ¡ / Complex analysis tasks</complex_analysis>
    <creative_writing>åˆ›æ„å†™ä½œ / Creative writing</creative_writing>
    <code_review>ä»£ç å®¡æŸ¥ / Code review</code_review>
  </optimal_use_cases>
</claude_model_characteristics>
```

#### Claudeè°ƒç”¨æœ€ä½³å®è·µ / Claude Calling Best Practices

```python
# Claudeè°ƒç”¨ä¼˜åŒ– / Claude calling optimization
class ClaudeClient:
    async def optimized_call(self, messages: List[Dict], task_type: str) -> Dict:
        """ä¼˜åŒ–çš„Claudeè°ƒç”¨ / Optimized Claude call"""
        # Claudeç‰¹å®šçš„æç¤ºæ ¼å¼ / Claude-specific prompt formatting
        formatted_messages = self._format_claude_messages(messages)

        params = {
            'model': 'claude-3-opus-20240229',
            'max_tokens': 4096,
            'system': self._get_system_prompt(task_type)
        }

        # æ ¹æ®ä»»åŠ¡è°ƒæ•´å‚æ•° / Adjust parameters based on task
        if task_type == 'creative':
            params['temperature'] = 0.8
        elif task_type == 'analytical':
            params['temperature'] = 0.1

        response = await self._call_anthropic_api(formatted_messages, **params)
        return self._parse_claude_response(response)

    def _format_claude_messages(self, messages: List[Dict]) -> str:
        """æ ¼å¼åŒ–Claudeæ¶ˆæ¯ / Format Claude messages"""
        formatted = []

        for msg in messages:
            if msg['role'] == 'system':
                # Claudeä½¿ç”¨systemå‚æ•° / Claude uses system parameter
                continue
            elif msg['role'] == 'user':
                formatted.append(f"Human: {msg['content']}")
            elif msg['role'] == 'assistant':
                formatted.append(f"Assistant: {msg['content']}")

        return "\n\n".join(formatted) + "\n\nAssistant:"
```

---

## Google Geminiè°ƒç”¨è§„åˆ™ / Google Gemini Calling Rules

### ğŸŒŸ 7. Geminiå¤šæ¨¡æ€ç‰¹æ€§ / Gemini Multimodal Features

#### å¤šæ¨¡æ€é›†æˆ / Multimodal Integration

```xml
<gemini_multimodal>
  <supported_modalities>
    <!-- æ”¯æŒçš„æ¨¡æ€ / Supported modalities -->
    <text_modality>æ–‡æœ¬æ¨¡æ€ / Text modality</text_modality>
    <image_modality>å›¾åƒæ¨¡æ€ / Image modality</image_modality>
    <audio_modality>éŸ³é¢‘æ¨¡æ€ / Audio modality</audio_modality>
    <video_modality>è§†é¢‘æ¨¡æ€ / Video modality</video_modality>
  </supported_modalities>

  <integration_patterns>
    <!-- é›†æˆæ¨¡å¼ / Integration patterns -->
    <text_only>çº¯æ–‡æœ¬æ¨¡å¼ / Text-only mode</text_only>
    <image_text>å›¾æ–‡æ··åˆ / Image-text hybrid</image_text>
    <multimodal_chain>å¤šæ¨¡æ€é“¾å¼è°ƒç”¨ / Multimodal chain calling</multimodal_chain>
  </integration_patterns>
</gemini_multimodal>
```

#### Geminiè°ƒç”¨å®ç° / Gemini Calling Implementation

```python
# Geminiå¤šæ¨¡æ€è°ƒç”¨ / Gemini multimodal calling
class GeminiClient:
    async def multimodal_completion(self, content: List[Dict]) -> Dict:
        """å¤šæ¨¡æ€å†…å®¹å®Œæˆ / Multimodal content completion"""
        # æ„å»ºå¤šæ¨¡æ€å†…å®¹ / Build multimodal content
        multimodal_content = []

        for item in content:
            if item['type'] == 'text':
                multimodal_content.append({
                    'text': item['content']
                })
            elif item['type'] == 'image':
                # å¤„ç†å›¾åƒè¾“å…¥ / Process image input
                image_data = await self._process_image(item['content'])
                multimodal_content.append({
                    'inline_data': {
                        'mime_type': image_data['mime_type'],
                        'data': image_data['base64_data']
                    }
                })

        # è°ƒç”¨Gemini API / Call Gemini API
        response = await self._call_gemini_api(multimodal_content)
        return self._parse_gemini_response(response)
```

---

## å›½äº§æ¨¡å‹è°ƒç”¨è§„åˆ™ / Domestic Model Calling Rules

### ğŸ‡¨ğŸ‡³ 8. å›½å†…æ¨¡å‹é›†æˆ / Domestic Model Integration

#### æ”¯æŒçš„å›½äº§æ¨¡å‹ / Supported Domestic Models

```xml
<domestic_models>
  <supported_providers>
    <!-- æ”¯æŒçš„æä¾›å•† / Supported providers -->
    <baidu_ernie>ç™¾åº¦æ–‡å¿ƒä¸€è¨€ / Baidu Ernie</baidu_ernie>
    <alibaba_qwen>é˜¿é‡Œé€šä¹‰åƒé—® / Alibaba Qwen</alibaba_qwen>
    <tencent_hunyuan>è…¾è®¯æ··å…ƒ / Tencent Hunyuan</tencent_hunyuan>
    <iflytek_spark>ç§‘å¤§è®¯é£æ˜Ÿç« / iFlyTek Spark</iflytek_spark>
  </supported_providers>

  <integration_requirements>
    <!-- é›†æˆè¦æ±‚ / Integration requirements -->
    <api_compatibility>APIå…¼å®¹æ€§ / API compatibility</api_compatibility>
    <data_compliance>æ•°æ®åˆè§„æ€§ / Data compliance</data_compliance>
    <performance_optimization>æ€§èƒ½ä¼˜åŒ– / Performance optimization</performance_optimization>
  </integration_requirements>
</domestic_models>
```

#### ç»Ÿä¸€æ¥å£é€‚é…å™¨ / Unified Interface Adapter

```python
# å›½äº§æ¨¡å‹ç»Ÿä¸€é€‚é…å™¨ / Domestic model unified adapter
class DomesticModelAdapter:
    def __init__(self, provider: str, config: Dict):
        self.provider = provider
        self.config = config
        self._initialize_client()

    async def unified_call(self, messages: List[Dict], **kwargs) -> Dict:
        """ç»Ÿä¸€çš„å›½äº§æ¨¡å‹è°ƒç”¨æ¥å£ / Unified domestic model calling interface"""
        # æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼ / Standardize message format
        standardized_messages = self._standardize_messages(messages)

        # é€‚é…æä¾›å•†ç‰¹å®šå‚æ•° / Adapt provider-specific parameters
        adapted_params = self._adapt_parameters(kwargs)

        # è°ƒç”¨å…·ä½“å®ç° / Call specific implementation
        if self.provider == 'baidu':
            return await self._call_ernie(standardized_messages, adapted_params)
        elif self.provider == 'alibaba':
            return await self._call_qwen(standardized_messages, adapted_params)
        elif self.provider == 'tencent':
            return await self._call_hunyuan(standardized_messages, adapted_params)

        raise ValueError(f"Unsupported provider: {self.provider}")

    def _standardize_messages(self, messages: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼ / Standardize message format"""
        # è½¬æ¢ä¸åŒæä¾›å•†çš„æ¶ˆæ¯æ ¼å¼ / Convert message formats for different providers
        pass
```

---

## é”™è¯¯å¤„ç†ç­–ç•¥ / Error Handling Strategies

### ğŸš¨ 9. å¼‚å¸¸åˆ†ç±»å’Œå¤„ç† / Exception Classification and Handling

#### é”™è¯¯ç±»å‹å®šä¹‰ / Error Type Definitions

```xml
<error_classification>
  <network_errors>
    <!-- ç½‘ç»œé”™è¯¯ / Network errors -->
    <connection_timeout>è¿æ¥è¶…æ—¶ / Connection timeout</connection_timeout>
    <dns_resolution>DNSè§£æå¤±è´¥ / DNS resolution failure</dns_resolution>
    <ssl_errors>SSLè¯ä¹¦é”™è¯¯ / SSL certificate errors</ssl_errors>
  </network_errors>

  <api_errors>
    <!-- APIé”™è¯¯ / API errors -->
    <rate_limit_exceeded>é€Ÿç‡é™åˆ¶è¶…é™ / Rate limit exceeded</rate_limit_exceeded>
    <quota_exceeded>é…é¢ç”¨å°½ / Quota exceeded</quota_exceeded>
    <invalid_request>æ— æ•ˆè¯·æ±‚ / Invalid request</invalid_request>
  </api_errors>

  <content_errors>
    <!-- å†…å®¹é”™è¯¯ / Content errors -->
    <content_filter>å†…å®¹è¿‡æ»¤ / Content filtering</content_filter>
    <safety_violation>å®‰å…¨è¿è§„ / Safety violation</safety_violation>
    <model_limitations>æ¨¡å‹é™åˆ¶ / Model limitations</model_limitations>
  </content_errors>
</error_classification>
```

#### é”™è¯¯å¤„ç†æ¡†æ¶ / Error Handling Framework

```python
# ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æ¡†æ¶ / Unified error handling framework
class APIErrorHandler:
    async def handle_api_call(self, api_call_func, *args, **kwargs):
        """å¤„ç†APIè°ƒç”¨çš„é”™è¯¯ / Handle API call errors"""
        retry_count = 0
        max_retries = self.config.get('max_retries', 3)

        while retry_count < max_retries:
            try:
                return await api_call_func(*args, **kwargs)
            except NetworkError as e:
                await self._handle_network_error(e, retry_count)
            except RateLimitError as e:
                await self._handle_rate_limit_error(e, retry_count)
            except APIError as e:
                await self._handle_api_error(e, retry_count)
            except Exception as e:
                await self._handle_unexpected_error(e, retry_count)

            retry_count += 1
            if retry_count < max_retries:
                await asyncio.sleep(self._calculate_backoff_delay(retry_count))

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ / All retries failed
        return await self._execute_fallback_strategy()

    async def _handle_rate_limit_error(self, error, retry_count):
        """å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯ / Handle rate limit error"""
        # è§£æé‡è¯•æ—¶é—´ / Parse retry time
        retry_after = self._parse_retry_after(error)

        # è®°å½•æ—¥å¿— / Log the event
        logger.warning(f"Rate limit exceeded, retrying after {retry_after}s")

        # ç­‰å¾…é‡è¯• / Wait for retry
        await asyncio.sleep(retry_after)
```

### ğŸ”„ 10. é‡è¯•å’Œå›é€€ç­–ç•¥ / Retry and Fallback Strategies

#### æ™ºèƒ½é‡è¯•æœºåˆ¶ / Intelligent Retry Mechanism

```python
# æ™ºèƒ½é‡è¯•ç­–ç•¥ / Intelligent retry strategy
class IntelligentRetryStrategy:
    def __init__(self):
        self.retry_delays = [1, 2, 4, 8, 16]  # æŒ‡æ•°é€€é¿ / Exponential backoff
        self.jitter_factor = 0.1  # æŠ–åŠ¨å› å­ / Jitter factor

    def should_retry(self, error: Exception, attempt: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯• / Determine if should retry"""
        if attempt >= len(self.retry_delays):
            return False

        # æ ¹æ®é”™è¯¯ç±»å‹åˆ¤æ–­ / Judge based on error type
        if isinstance(error, (ConnectionError, TimeoutError)):
            return True
        elif isinstance(error, RateLimitError):
            return True
        elif isinstance(error, ServerError) and error.status_code >= 500:
            return True

        return False

    def get_retry_delay(self, attempt: int) -> float:
        """è·å–é‡è¯•å»¶è¿Ÿ / Get retry delay"""
        if attempt >= len(self.retry_delays):
            return self.retry_delays[-1]

        delay = self.retry_delays[attempt]
        # æ·»åŠ æŠ–åŠ¨é¿å…æƒŠç¾¤æ•ˆåº” / Add jitter to avoid thundering herd
        jitter = delay * self.jitter_factor * random.random()
        return delay + jitter
```

---

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§ / Performance Optimization Techniques

### âš¡ 11. ç¼“å­˜ç­–ç•¥ / Caching Strategies

#### å¤šå±‚ç¼“å­˜æ¶æ„ / Multi-Level Caching Architecture

```xml
<caching_architecture>
  <cache_layers>
    <!-- ç¼“å­˜å±‚çº§ / Cache layers -->
    <memory_cache>å†…å­˜ç¼“å­˜ / Memory cache</memory_cache>
    <distributed_cache>åˆ†å¸ƒå¼ç¼“å­˜ / Distributed cache</distributed_cache>
    <persistent_cache>æŒä¹…åŒ–ç¼“å­˜ / Persistent cache</persistent_cache>
  </cache_layers>

  <cache_strategies>
    <!-- ç¼“å­˜ç­–ç•¥ / Cache strategies -->
    <semantic_cache>è¯­ä¹‰ç¼“å­˜ / Semantic caching</semantic_cache>
    <response_cache>å“åº”ç¼“å­˜ / Response caching</response_cache>
    <embedding_cache>åµŒå…¥ç¼“å­˜ / Embedding caching</embedding_cache>
  </cache_strategies>
</caching_architecture>
```

#### è¯­ä¹‰ç¼“å­˜å®ç° / Semantic Caching Implementation

```python
# è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿ / Semantic caching system
class SemanticCache:
    def __init__(self, embedding_model, similarity_threshold=0.85):
        self.embedding_model = embedding_model
        self.similarity_threshold = similarity_threshold
        self.cache = {}

    async def get_cached_response(self, query: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„å“åº” / Get cached response"""
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥ / Generate query embedding
        query_embedding = await self._get_embedding(query)

        # æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢ / Find similar queries
        best_match = None
        best_similarity = 0

        for cached_query, (embedding, response) in self.cache.items():
            similarity = self._calculate_similarity(query_embedding, embedding)
            if similarity > best_similarity and similarity >= self.similarity_threshold:
                best_similarity = similarity
                best_match = response

        return best_match

    async def cache_response(self, query: str, response: str):
        """ç¼“å­˜å“åº” / Cache response"""
        query_embedding = await self._get_embedding(query)
        self.cache[query] = (query_embedding, response)

        # æ¸…ç†è¿‡æœŸç¼“å­˜ / Clean up expired cache
        if len(self.cache) > self.max_cache_size:
            await self._cleanup_cache()
```

### ğŸ“Š 12. è¯·æ±‚æ‰¹å¤„ç†å’Œå¹¶å‘æ§åˆ¶ / Request Batching and Concurrency Control

#### æ‰¹é‡è¯·æ±‚ä¼˜åŒ– / Batch Request Optimization

```python
# è¯·æ±‚æ‰¹å¤„ç†å™¨ / Request batch processor
class BatchRequestProcessor:
    def __init__(self, batch_size=10, max_wait_time=1.0):
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.request_queue = asyncio.Queue()
        self.processing_task = None

    async def add_request(self, request: Dict) -> asyncio.Future:
        """æ·»åŠ è¯·æ±‚åˆ°æ‰¹å¤„ç†é˜Ÿåˆ— / Add request to batch processing queue"""
        future = asyncio.Future()
        await self.request_queue.put((request, future))

        # å¯åŠ¨æ‰¹å¤„ç†ä»»åŠ¡ / Start batch processing task
        if self.processing_task is None or self.processing_task.done():
            self.processing_task = asyncio.create_task(self._process_batch())

        return future

    async def _process_batch(self):
        """å¤„ç†è¯·æ±‚æ‰¹æ¬¡ / Process request batch"""
        while True:
            batch = []
            start_time = time.time()

            # æ”¶é›†æ‰¹æ¬¡è¯·æ±‚ / Collect batch requests
            while len(batch) < self.batch_size:
                try:
                    # è®¾ç½®è¶…æ—¶ / Set timeout
                    request, future = await asyncio.wait_for(
                        self.request_queue.get(),
                        timeout=self.max_wait_time
                    )
                    batch.append((request, future))
                except asyncio.TimeoutError:
                    break

                # æ£€æŸ¥ç­‰å¾…æ—¶é—´ / Check wait time
                if time.time() - start_time >= self.max_wait_time:
                    break

            if not batch:
                break

            # æ‰¹é‡å¤„ç†è¯·æ±‚ / Process batch requests
            try:
                responses = await self._execute_batch([req for req, _ in batch])
                for (request, future), response in zip(batch, responses):
                    future.set_result(response)
            except Exception as e:
                # å¤„ç†æ‰¹å¤„ç†é”™è¯¯ / Handle batch processing error
                for request, future in batch:
                    future.set_exception(e)
```

---

## å®‰å…¨å’Œåˆè§„è¦æ±‚ / Security and Compliance Requirements

### ğŸ”’ 13. æ•°æ®ä¿æŠ¤å’Œéšç§ / Data Protection and Privacy

#### æ•°æ®å¤„ç†å®‰å…¨ / Data Processing Security

```xml
<data_security>
  <encryption_standards>
    <!-- åŠ å¯†æ ‡å‡† / Encryption standards -->
    <data_in_transit>ä¼ è¾“ä¸­æ•°æ®åŠ å¯† / Data in transit encryption</data_in_transit>
    <data_at_rest>é™æ€æ•°æ®åŠ å¯† / Data at rest encryption</data_at_rest>
    <key_management>å¯†é’¥ç®¡ç† / Key management</key_management>
  </encryption_standards>

  <privacy_protection>
    <!-- éšç§ä¿æŠ¤ / Privacy protection -->
    <data_minimization>æ•°æ®æœ€å°åŒ– / Data minimization</data_minimization>
    <consent_management>åŒæ„ç®¡ç† / Consent management</consent_management>
    <right_to_be_forgotten>è¢«é—å¿˜æƒ / Right to be forgotten</right_to_be_forgotten>
  </privacy_protection>
</data_security>
```

#### åˆè§„æ£€æŸ¥æ¸…å• / Compliance Checklist

```python
# åˆè§„æ£€æŸ¥å™¨ / Compliance checker
class ComplianceChecker:
    def __init__(self):
        self.compliance_rules = self._load_compliance_rules()

    def check_request_compliance(self, request: Dict) -> ComplianceResult:
        """æ£€æŸ¥è¯·æ±‚åˆè§„æ€§ / Check request compliance"""
        result = ComplianceResult()

        # æ£€æŸ¥æ•°æ®å†…å®¹ / Check data content
        if self._contains_sensitive_data(request):
            result.add_violation("Sensitive data detected")

        # æ£€æŸ¥åœ°ç†ä½ç½®é™åˆ¶ / Check geographic restrictions
        if self._violates_geo_restrictions(request):
            result.add_violation("Geographic restriction violation")

        # æ£€æŸ¥å†…å®¹å®‰å…¨ / Check content safety
        if self._contains_harmful_content(request):
            result.add_violation("Harmful content detected")

        return result

    def check_response_compliance(self, response: Dict) -> ComplianceResult:
        """æ£€æŸ¥å“åº”åˆè§„æ€§ / Check response compliance"""
        result = ComplianceResult()

        # æ£€æŸ¥è¾“å‡ºå†…å®¹ / Check output content
        if self._contains_disallowed_content(response):
            result.add_violation("Disallowed content in response")

        # æ£€æŸ¥æ•°æ®æ³„éœ² / Check data leakage
        if self._contains_data_leakage(response):
            result.add_violation("Potential data leakage")

        return result
```

---

## ğŸ“… å¼€å‘è¿›åº¦æ—¶é—´è¡¨æ›´æ–°è§„åˆ™ / Development Progress Timestamp Update Rules

> **é“å¾‹ / Iron Rule**: æ¯æ¬¡å¼€å‘æ›´æ–°æ—¶ï¼Œæ—¶é—´è¿›åº¦è¡¨å¿…é¡»ä½¿ç”¨æœ¬æœºç”µè„‘å½“å‰çš„å®æ—¶æ—¥æœŸæ—¶é—´

**æœ€åæ›´æ–° / Last updated: 2025å¹´09æœˆ02æ—¥ 11:09:34**
**æ–‡æ¡£ç‰ˆæœ¬ / Document version: 1.0.0**
